{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees are the representation of \"rule\", that we can easily understand in real world. In sort, it's a bunch of `if-then-else` statement. If you ever create a rule of "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute Selection Measure: Split Your Tree (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are mainly two types of measurement to make a decision in a tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini Index\n",
    "\n",
    "$$\n",
    "    gini = 1 - \\sum_j{p_j^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Gain \n",
    "In information gain, we will use Entropy as a measure to split the tree. The intuition of Entropy is : \n",
    "\n",
    "$$\n",
    "    entropy =  - \\sum_j{p_j \\times log_2(p_j)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you can see, there's not much different from both measurement. However, Enrtopy can cost more computational processes compared to Gini. By default, Sklearn will use Gini to split the tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After solving the split problem, the decision tree has one other problem to solve: it needs to know when to stop growing. If the tree grow indefinitely (and it can) it will end up splitting all data points until they are perfectly classified and yield an overly specific model (overfitting; or the case of high variance and low bias). One approach is to set a pre-determined number of levels upon which we command our tree to stop growing. This is an approach known as pre-pruning, but it has the obvious downside of us having to make an informed guess around the optimal depth / size of the tree. The alternative, post-pruning relies on a strategy that grow the tree to too large a size and then pruning it later on once all important structures and classification patterns were discovered. Getting the best fit decision tree model means we manage to strike a good balance with our bias-variance and precision-recall tradeoffs.\n",
    "\n",
    "Currently, Sklearn only provide [post-pruning algorithm](https://scikit-learn.org/dev/auto_examples/tree/plot_cost_complexity_pruning.html) to reduce the complexity cost and overfitting threat of tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the best-value of Decision Tree is  its capability in classifying the multiclass problem with a low computation cost and reasonable performance. In our case, let's try Iris Dataset, containing more than two classes of flowers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_len(cm)</th>\n",
       "      <th>sepal_width(cm)</th>\n",
       "      <th>petal_len(cm)</th>\n",
       "      <th>petal_width(cm)</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_len(cm)  sepal_width(cm)  petal_len(cm)  petal_width(cm)  class\n",
       "0            5.1              3.5            1.4              0.2      0\n",
       "1            4.9              3.0            1.4              0.2      0\n",
       "2            4.7              3.2            1.3              0.2      0\n",
       "3            4.6              3.1            1.5              0.2      0\n",
       "4            5.0              3.6            1.4              0.2      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iris = pd.DataFrame(iris['data'], columns=['sepal_len(cm)','sepal_width(cm)','petal_len(cm)','petal_width(cm)'])\n",
    "df_iris['class'] = iris['target']\n",
    "df_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(df_iris.loc[:,df_iris.columns != 'class'], \n",
    "                                                      df_iris['class'],\n",
    "                                                      test_size = 0.2, \n",
    "                                                      random_state = int(time.time())\n",
    "                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 1, 1, 0, 0, 0, 1, 2, 1, 0, 2, 2, 1, 2, 1, 2, 2, 0, 1, 2,\n",
       "       1, 2, 1, 2, 2, 1, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_valid)\n",
    "# clf.predict_proba(X_valid) # return the probability of each class\n",
    "# clf.predict_log_proba(X_valid) # return the log of probabiliy of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      0.92      0.96        13\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_valid, clf.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv(\"data/titanic/train.csv\")\n",
    "test = pd.read_csv(\"data/titanic/test.csv\")\n",
    "\n",
    "# Convert categorical variable to numeric\n",
    "titanic[\"Sex_cleaned\"]=np.where(titanic[\"Sex\"]==\"male\",0,1)\n",
    "titanic[\"Embarked_cleaned\"]=np.where(titanic[\"Embarked\"]==\"S\",0,\n",
    "                                  np.where(titanic[\"Embarked\"]==\"C\",1,\n",
    "                                           np.where(titanic[\"Embarked\"]==\"Q\",2,3)\n",
    "                                          )\n",
    "                                 )\n",
    "test[\"Sex_cleaned\"]=np.where(test[\"Sex\"]==\"male\",0,1)\n",
    "test[\"Embarked_cleaned\"]=np.where(test[\"Embarked\"]==\"S\",0,\n",
    "                                  np.where(test[\"Embarked\"]==\"C\",1,\n",
    "                                           np.where(test[\"Embarked\"]==\"Q\",2,3)\n",
    "                                          )\n",
    "                                 )\n",
    "\n",
    "# Cleaning train of NaN\n",
    "titanic=titanic[[\n",
    "    \"Survived\",\n",
    "    \"Pclass\",\n",
    "    \"Sex_cleaned\",\n",
    "    \"Age\",\n",
    "    \"SibSp\",\n",
    "    \"Parch\",\n",
    "    \"Fare\",\n",
    "    \"Embarked_cleaned\"\n",
    "]].dropna(axis=0, how='any')\n",
    "\n",
    "#filling test's NaN, because we can't evaluate the number if it's NaN\n",
    "test=test[[\n",
    "    \"Pclass\",\n",
    "    \"Sex_cleaned\",\n",
    "    \"Age\",\n",
    "    \"SibSp\",\n",
    "    \"Parch\",\n",
    "    \"Fare\",\n",
    "    \"Embarked_cleaned\"\n",
    "]].fillna(value=0)\n",
    "\n",
    "# Split dataset in training and test datasets\n",
    "# train, valid = train_test_split(titanic, test_size=0.2, random_state=int(time.time()))\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(titanic.loc[:,titanic.columns != 'Survived'], \n",
    "                                                      titanic['Survived'],\n",
    "                                                      test_size = 0.2, \n",
    "                                                      random_state = int(time.time())\n",
    "                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.79        89\n",
      "           1       0.65      0.72      0.68        54\n",
      "\n",
      "    accuracy                           0.75       143\n",
      "   macro avg       0.73      0.74      0.74       143\n",
      "weighted avg       0.76      0.75      0.75       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_valid, clf.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify\"> \n",
    "\n",
    "Note : \n",
    "\n",
    "If you notice, sklearn's tree gives different results overtime if you re-create the model (the tree/classifier). This is explained in the documentation. The default values for the parameters controlling the size of the trees (e.g. max_depth, min_samples_leaf, etc.) lead to fully grown and unpruned trees which can potentially be very large on some data sets. To reduce memory consumption, the complexity and size of the trees should be controlled by setting those parameter values.\n",
    "\n",
    "The features are always randomly permuted at each split. Therefore, the best found split may vary, even with the same training data and *max_features = n_features*, if the improvement of the criterion is identical for several splits enumerated during the search of the best split. To obtain a deterministic behaviour during fitting, random_state has to be fixed.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold Cross Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of time, we use a validation strategy by splitting the training set into : Train-Validation data, followed by training the model into train, and test the model with validation data then ended up with predicting the test data. \n",
    "\n",
    "This workflow is simple, but leaves some uncertainty in measuring the stability of the model. So let's try K-fold Cross validation by iteratively measure the performance of the model within K-sets of train-validation data. K-fold Cross Validation let us train the model into the whole training data, so we can measure its stability over different set of Train-Validation data.\n",
    "\n",
    "If you need more understanding in how K-fold Cross Validation works, please check-out our articles [here](google.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : [0.71604938 0.725      0.75949367 0.75949367 0.74683544 0.74683544\n",
      " 0.78481013 0.78481013 0.81012658]\n",
      "Average : 0.7592727162230211 \n",
      "\n",
      "Precision : [0.625      0.7037037  0.67567568 0.67567568 0.7        0.7\n",
      " 0.77777778 0.71428571 0.77419355]\n",
      "Average : 0.705145788389516 \n",
      "\n",
      "Recall : [0.75757576 0.57575758 0.78125    0.78125    0.65625    0.65625\n",
      " 0.65625    0.78125    0.75      ]\n",
      "Average : 0.7106481481481483 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(random_state = 10)\n",
    "k = 9 # Number of K-sets\n",
    "# Disclaimer : This is not how you should measure your score (acc, prec, recal) in k-fold cross validation. \n",
    "# It is redundant and wastes resources (computing jobs). But for convenient purpose, let's do this \n",
    "kcv_acc = cross_val_score(clf, titanic.loc[:, titanic.columns != 'Survived'], titanic['Survived'], cv=k)\n",
    "kcv_prec = cross_val_score(clf, titanic.loc[:, titanic.columns != 'Survived'], titanic['Survived'], cv=k, scoring='precision')\n",
    "kcv_recl = cross_val_score(clf, titanic.loc[:, titanic.columns != 'Survived'], titanic['Survived'], cv=k, scoring='recall')\n",
    "\n",
    "print(\"Accuracy : {}\".format(kcv_acc))\n",
    "print(\"Average : {} \\n\".format(np.mean(kcv_acc)))\n",
    "print(\"Precision : {}\".format(kcv_prec))\n",
    "print(\"Average : {} \\n\".format(np.mean(kcv_prec)))\n",
    "print(\"Recall : {}\".format(kcv_recl))\n",
    "print(\"Average : {} \\n\".format(np.mean(kcv_recl)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Tree\n",
    "Let's try to visualize our model wich trained with Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(df_iris.loc[:,df_iris.columns != 'class'], \n",
    "                                                      df_iris['class'],\n",
    "                                                      test_size = 0.2, \n",
    "                                                      random_state = int(time.time())\n",
    "                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(152.6153846153846, 343.2, 'X[3] <= 0.75\\ngini = 0.666\\nsamples = 120\\nvalue = [42, 41, 37]'),\n",
       " Text(114.46153846153845, 290.4, 'gini = 0.0\\nsamples = 42\\nvalue = [42, 0, 0]'),\n",
       " Text(190.76923076923077, 290.4, 'X[2] <= 4.75\\ngini = 0.499\\nsamples = 78\\nvalue = [0, 41, 37]'),\n",
       " Text(76.3076923076923, 237.59999999999997, 'X[3] <= 1.65\\ngini = 0.053\\nsamples = 37\\nvalue = [0, 36, 1]'),\n",
       " Text(38.15384615384615, 184.79999999999998, 'gini = 0.0\\nsamples = 36\\nvalue = [0, 36, 0]'),\n",
       " Text(114.46153846153845, 184.79999999999998, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(305.2307692307692, 237.59999999999997, 'X[3] <= 1.75\\ngini = 0.214\\nsamples = 41\\nvalue = [0, 5, 36]'),\n",
       " Text(190.76923076923077, 184.79999999999998, 'X[2] <= 4.95\\ngini = 0.5\\nsamples = 8\\nvalue = [0, 4, 4]'),\n",
       " Text(152.6153846153846, 131.99999999999997, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(228.9230769230769, 131.99999999999997, 'X[3] <= 1.55\\ngini = 0.444\\nsamples = 6\\nvalue = [0, 2, 4]'),\n",
       " Text(190.76923076923077, 79.19999999999999, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(267.0769230769231, 79.19999999999999, 'X[0] <= 6.95\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 2, 1]'),\n",
       " Text(228.9230769230769, 26.399999999999977, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(305.2307692307692, 26.399999999999977, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(419.6923076923077, 184.79999999999998, 'X[2] <= 4.85\\ngini = 0.059\\nsamples = 33\\nvalue = [0, 1, 32]'),\n",
       " Text(381.53846153846155, 131.99999999999997, 'X[0] <= 5.95\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 1, 2]'),\n",
       " Text(343.38461538461536, 79.19999999999999, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(419.6923076923077, 79.19999999999999, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(457.8461538461538, 131.99999999999997, 'gini = 0.0\\nsamples = 30\\nvalue = [0, 0, 30]')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "tree.plot_tree(clf) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to export the text, you can use `export_text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- petal width (cm) <= 0.75\n",
      "|   |--- class: 0\n",
      "|--- petal width (cm) >  0.75\n",
      "|   |--- petal length (cm) <= 4.75\n",
      "|   |   |--- petal width (cm) <= 1.65\n",
      "|   |   |   |--- class: 1\n",
      "|   |   |--- petal width (cm) >  1.65\n",
      "|   |   |   |--- class: 2\n",
      "|   |--- petal length (cm) >  4.75\n",
      "|   |   |--- petal width (cm) <= 1.75\n",
      "|   |   |   |--- petal length (cm) <= 4.95\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- petal length (cm) >  4.95\n",
      "|   |   |   |   |--- petal width (cm) <= 1.55\n",
      "|   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |--- petal width (cm) >  1.55\n",
      "|   |   |   |   |   |--- sepal length (cm) <= 6.95\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- sepal length (cm) >  6.95\n",
      "|   |   |   |   |   |   |--- class: 2\n",
      "|   |   |--- petal width (cm) >  1.75\n",
      "|   |   |   |--- petal length (cm) <= 4.85\n",
      "|   |   |   |   |--- sepal length (cm) <= 5.95\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- sepal length (cm) >  5.95\n",
      "|   |   |   |   |   |--- class: 2\n",
      "|   |   |   |--- petal length (cm) >  4.85\n",
      "|   |   |   |   |--- class: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = tree.export_text(clf, feature_names=iris['feature_names'])\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also plot using `Graphviz` by running `conda install -c anaconda graphviz` followed by `conda install -c anaconda python-graphviz`. Graphviz is graph visualization tools, working with `dot` data. Please visit [Graphviz Documentation Page](https://www.graphviz.org) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"625pt\" height=\"685pt\"\r\n",
       " viewBox=\"0.00 0.00 625.00 685.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 681)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-681 621,-681 621,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"241.5,-677 116.5,-677 116.5,-609 241.5,-609 241.5,-677\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"179\" y=\"-661.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X[3] &lt;= 0.75</text>\r\n",
       "<text text-anchor=\"middle\" x=\"179\" y=\"-646.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.666</text>\r\n",
       "<text text-anchor=\"middle\" x=\"179\" y=\"-631.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 120</text>\r\n",
       "<text text-anchor=\"middle\" x=\"179\" y=\"-616.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [42, 41, 37]</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"168,-565.5 56,-565.5 56,-512.5 168,-512.5 168,-565.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"112\" y=\"-550.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"112\" y=\"-535.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 42</text>\r\n",
       "<text text-anchor=\"middle\" x=\"112\" y=\"-520.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [42, 0, 0]</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M157.247,-608.884C149.951,-597.776 141.803,-585.372 134.454,-574.184\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"137.179,-571.957 128.763,-565.52 131.328,-575.8 137.179,-571.957\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"123.693\" y=\"-586.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"305.5,-573 186.5,-573 186.5,-505 305.5,-505 305.5,-573\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"246\" y=\"-557.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X[2] &lt;= 4.75</text>\r\n",
       "<text text-anchor=\"middle\" x=\"246\" y=\"-542.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.499</text>\r\n",
       "<text text-anchor=\"middle\" x=\"246\" y=\"-527.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 78</text>\r\n",
       "<text text-anchor=\"middle\" x=\"246\" y=\"-512.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 41, 37]</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>0&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M200.753,-608.884C206.428,-600.243 212.619,-590.819 218.548,-581.793\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"221.562,-583.579 224.127,-573.299 215.711,-579.736 221.562,-583.579\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"229.197\" y=\"-594.08\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"237,-469 125,-469 125,-401 237,-401 237,-469\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"181\" y=\"-453.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X[3] &lt;= 1.65</text>\r\n",
       "<text text-anchor=\"middle\" x=\"181\" y=\"-438.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.053</text>\r\n",
       "<text text-anchor=\"middle\" x=\"181\" y=\"-423.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 37</text>\r\n",
       "<text text-anchor=\"middle\" x=\"181\" y=\"-408.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 36, 1]</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M224.896,-504.884C219.39,-496.243 213.385,-486.819 207.633,-477.793\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"210.546,-475.852 202.22,-469.299 204.643,-479.614 210.546,-475.852\"/>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"367,-469 255,-469 255,-401 367,-401 367,-469\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"311\" y=\"-453.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X[3] &lt;= 1.75</text>\r\n",
       "<text text-anchor=\"middle\" x=\"311\" y=\"-438.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.214</text>\r\n",
       "<text text-anchor=\"middle\" x=\"311\" y=\"-423.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 41</text>\r\n",
       "<text text-anchor=\"middle\" x=\"311\" y=\"-408.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 5, 36]</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;6 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>2&#45;&gt;6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M267.104,-504.884C272.61,-496.243 278.615,-486.819 284.367,-477.793\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"287.357,-479.614 289.78,-469.299 281.454,-475.852 287.357,-479.614\"/>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"112,-357.5 7.10543e-015,-357.5 7.10543e-015,-304.5 112,-304.5 112,-357.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"56\" y=\"-342.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"56\" y=\"-327.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 36</text>\r\n",
       "<text text-anchor=\"middle\" x=\"56\" y=\"-312.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 36, 0]</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M140.416,-400.884C125.86,-389.006 109.488,-375.646 95.0637,-363.876\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"97.2351,-361.13 87.2744,-357.52 92.8095,-366.554 97.2351,-361.13\"/>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"235.5,-357.5 130.5,-357.5 130.5,-304.5 235.5,-304.5 235.5,-357.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"183\" y=\"-342.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"183\" y=\"-327.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"middle\" x=\"183\" y=\"-312.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 0, 1]</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;5 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>3&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M181.649,-400.884C181.859,-390.216 182.091,-378.352 182.304,-367.519\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"185.803,-367.587 182.5,-357.52 178.804,-367.449 185.803,-367.587\"/>\r\n",
       "</g>\r\n",
       "<!-- 7 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>7</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"361.5,-365 256.5,-365 256.5,-297 361.5,-297 361.5,-365\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"309\" y=\"-349.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X[2] &lt;= 4.95</text>\r\n",
       "<text text-anchor=\"middle\" x=\"309\" y=\"-334.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"309\" y=\"-319.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 8</text>\r\n",
       "<text text-anchor=\"middle\" x=\"309\" y=\"-304.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 4, 4]</text>\r\n",
       "</g>\r\n",
       "<!-- 6&#45;&gt;7 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>6&#45;&gt;7</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M310.351,-400.884C310.192,-392.778 310.019,-383.982 309.852,-375.472\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"313.348,-375.229 309.653,-365.299 306.35,-375.366 313.348,-375.229\"/>\r\n",
       "</g>\r\n",
       "<!-- 14 -->\r\n",
       "<g id=\"node15\" class=\"node\"><title>14</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"492,-365 380,-365 380,-297 492,-297 492,-365\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"436\" y=\"-349.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X[2] &lt;= 4.85</text>\r\n",
       "<text text-anchor=\"middle\" x=\"436\" y=\"-334.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.059</text>\r\n",
       "<text text-anchor=\"middle\" x=\"436\" y=\"-319.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 33</text>\r\n",
       "<text text-anchor=\"middle\" x=\"436\" y=\"-304.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 1, 32]</text>\r\n",
       "</g>\r\n",
       "<!-- 6&#45;&gt;14 -->\r\n",
       "<g id=\"edge14\" class=\"edge\"><title>6&#45;&gt;14</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M351.584,-400.884C362.936,-391.62 375.394,-381.455 387.17,-371.845\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"389.657,-374.333 395.192,-365.299 385.231,-368.91 389.657,-374.333\"/>\r\n",
       "</g>\r\n",
       "<!-- 8 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"239.5,-253.5 134.5,-253.5 134.5,-200.5 239.5,-200.5 239.5,-253.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"187\" y=\"-238.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"187\" y=\"-223.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 2</text>\r\n",
       "<text text-anchor=\"middle\" x=\"187\" y=\"-208.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 2, 0]</text>\r\n",
       "</g>\r\n",
       "<!-- 7&#45;&gt;8 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>7&#45;&gt;8</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M269.39,-296.884C255.315,-285.116 239.5,-271.894 225.518,-260.203\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"227.441,-257.249 217.524,-253.52 222.951,-262.619 227.441,-257.249\"/>\r\n",
       "</g>\r\n",
       "<!-- 9 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>9</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"362.5,-261 257.5,-261 257.5,-193 362.5,-193 362.5,-261\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"310\" y=\"-245.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X[3] &lt;= 1.55</text>\r\n",
       "<text text-anchor=\"middle\" x=\"310\" y=\"-230.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.444</text>\r\n",
       "<text text-anchor=\"middle\" x=\"310\" y=\"-215.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 6</text>\r\n",
       "<text text-anchor=\"middle\" x=\"310\" y=\"-200.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 2, 4]</text>\r\n",
       "</g>\r\n",
       "<!-- 7&#45;&gt;9 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>7&#45;&gt;9</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M309.325,-296.884C309.404,-288.778 309.49,-279.982 309.574,-271.472\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"313.075,-271.333 309.674,-261.299 306.076,-271.265 313.075,-271.333\"/>\r\n",
       "</g>\r\n",
       "<!-- 10 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>10</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"239.5,-149.5 134.5,-149.5 134.5,-96.5 239.5,-96.5 239.5,-149.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"187\" y=\"-134.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"187\" y=\"-119.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 3</text>\r\n",
       "<text text-anchor=\"middle\" x=\"187\" y=\"-104.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 0, 3]</text>\r\n",
       "</g>\r\n",
       "<!-- 9&#45;&gt;10 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>9&#45;&gt;10</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M270.065,-192.884C255.875,-181.116 239.931,-167.894 225.833,-156.203\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"227.706,-153.209 217.774,-149.52 223.237,-158.597 227.706,-153.209\"/>\r\n",
       "</g>\r\n",
       "<!-- 11 -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>11</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"362.5,-157 257.5,-157 257.5,-89 362.5,-89 362.5,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"310\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X[0] &lt;= 6.95</text>\r\n",
       "<text text-anchor=\"middle\" x=\"310\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.444</text>\r\n",
       "<text text-anchor=\"middle\" x=\"310\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 3</text>\r\n",
       "<text text-anchor=\"middle\" x=\"310\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 2, 1]</text>\r\n",
       "</g>\r\n",
       "<!-- 9&#45;&gt;11 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>9&#45;&gt;11</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M310,-192.884C310,-184.778 310,-175.982 310,-167.472\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"313.5,-167.299 310,-157.299 306.5,-167.299 313.5,-167.299\"/>\r\n",
       "</g>\r\n",
       "<!-- 12 -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>12</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"300.5,-53 195.5,-53 195.5,-0 300.5,-0 300.5,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"248\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"248\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 2</text>\r\n",
       "<text text-anchor=\"middle\" x=\"248\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 2, 0]</text>\r\n",
       "</g>\r\n",
       "<!-- 11&#45;&gt;12 -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>11&#45;&gt;12</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M288.315,-88.9485C282.554,-80.1664 276.319,-70.6629 270.514,-61.815\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"273.297,-59.6779 264.885,-53.2367 267.445,-63.5178 273.297,-59.6779\"/>\r\n",
       "</g>\r\n",
       "<!-- 13 -->\r\n",
       "<g id=\"node14\" class=\"node\"><title>13</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"423.5,-53 318.5,-53 318.5,-0 423.5,-0 423.5,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"371\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"371\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"middle\" x=\"371\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 0, 1]</text>\r\n",
       "</g>\r\n",
       "<!-- 11&#45;&gt;13 -->\r\n",
       "<g id=\"edge13\" class=\"edge\"><title>11&#45;&gt;13</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M331.335,-88.9485C337.004,-80.1664 343.138,-70.6629 348.85,-61.815\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"351.904,-63.5365 354.387,-53.2367 346.023,-59.7402 351.904,-63.5365\"/>\r\n",
       "</g>\r\n",
       "<!-- 15 -->\r\n",
       "<g id=\"node16\" class=\"node\"><title>15</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"486.5,-261 381.5,-261 381.5,-193 486.5,-193 486.5,-261\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"434\" y=\"-245.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X[0] &lt;= 5.95</text>\r\n",
       "<text text-anchor=\"middle\" x=\"434\" y=\"-230.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.444</text>\r\n",
       "<text text-anchor=\"middle\" x=\"434\" y=\"-215.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 3</text>\r\n",
       "<text text-anchor=\"middle\" x=\"434\" y=\"-200.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 1, 2]</text>\r\n",
       "</g>\r\n",
       "<!-- 14&#45;&gt;15 -->\r\n",
       "<g id=\"edge15\" class=\"edge\"><title>14&#45;&gt;15</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M435.351,-296.884C435.192,-288.778 435.019,-279.982 434.852,-271.472\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"438.348,-271.229 434.653,-261.299 431.35,-271.366 438.348,-271.229\"/>\r\n",
       "</g>\r\n",
       "<!-- 18 -->\r\n",
       "<g id=\"node19\" class=\"node\"><title>18</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"617,-253.5 505,-253.5 505,-200.5 617,-200.5 617,-253.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"561\" y=\"-238.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"561\" y=\"-223.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 30</text>\r\n",
       "<text text-anchor=\"middle\" x=\"561\" y=\"-208.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 0, 30]</text>\r\n",
       "</g>\r\n",
       "<!-- 14&#45;&gt;18 -->\r\n",
       "<g id=\"edge18\" class=\"edge\"><title>14&#45;&gt;18</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M476.584,-296.884C491.14,-285.006 507.512,-271.646 521.936,-259.876\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"524.191,-262.554 529.726,-253.52 519.765,-257.13 524.191,-262.554\"/>\r\n",
       "</g>\r\n",
       "<!-- 16 -->\r\n",
       "<g id=\"node17\" class=\"node\"><title>16</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"485.5,-149.5 380.5,-149.5 380.5,-96.5 485.5,-96.5 485.5,-149.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"433\" y=\"-134.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"433\" y=\"-119.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"middle\" x=\"433\" y=\"-104.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 1, 0]</text>\r\n",
       "</g>\r\n",
       "<!-- 15&#45;&gt;16 -->\r\n",
       "<g id=\"edge16\" class=\"edge\"><title>15&#45;&gt;16</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M433.675,-192.884C433.572,-182.326 433.457,-170.597 433.352,-159.854\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"436.848,-159.485 433.25,-149.52 429.848,-159.554 436.848,-159.485\"/>\r\n",
       "</g>\r\n",
       "<!-- 17 -->\r\n",
       "<g id=\"node18\" class=\"node\"><title>17</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"608.5,-149.5 503.5,-149.5 503.5,-96.5 608.5,-96.5 608.5,-149.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"556\" y=\"-134.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"556\" y=\"-119.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 2</text>\r\n",
       "<text text-anchor=\"middle\" x=\"556\" y=\"-104.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 0, 2]</text>\r\n",
       "</g>\r\n",
       "<!-- 15&#45;&gt;17 -->\r\n",
       "<g id=\"edge17\" class=\"edge\"><title>15&#45;&gt;17</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M473.61,-192.884C487.685,-181.116 503.5,-167.894 517.482,-156.203\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"520.049,-158.619 525.476,-149.52 515.559,-153.249 520.049,-158.619\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x16e0f8bb5c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"785pt\" height=\"790pt\"\r\n",
       " viewBox=\"0.00 0.00 785.00 790.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 786)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-786 781,-786 781,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<path fill=\"#fffdfc\" stroke=\"black\" d=\"M273,-782C273,-782 138,-782 138,-782 132,-782 126,-776 126,-770 126,-770 126,-711 126,-711 126,-705 132,-699 138,-699 138,-699 273,-699 273,-699 279,-699 285,-705 285,-711 285,-711 285,-770 285,-770 285,-776 279,-782 273,-782\"/>\r\n",
       "<text text-anchor=\"start\" x=\"134\" y=\"-766.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) ≤ 0.75</text>\r\n",
       "<text text-anchor=\"start\" x=\"168\" y=\"-751.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.666</text>\r\n",
       "<text text-anchor=\"start\" x=\"158\" y=\"-736.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 120</text>\r\n",
       "<text text-anchor=\"start\" x=\"145\" y=\"-721.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [42, 41, 37]</text>\r\n",
       "<text text-anchor=\"start\" x=\"159.5\" y=\"-706.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M174,-655.5C174,-655.5 77,-655.5 77,-655.5 71,-655.5 65,-649.5 65,-643.5 65,-643.5 65,-599.5 65,-599.5 65,-593.5 71,-587.5 77,-587.5 77,-587.5 174,-587.5 174,-587.5 180,-587.5 186,-593.5 186,-599.5 186,-599.5 186,-643.5 186,-643.5 186,-649.5 180,-655.5 174,-655.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"96.5\" y=\"-640.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"82\" y=\"-625.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 42</text>\r\n",
       "<text text-anchor=\"start\" x=\"73\" y=\"-610.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [42, 0, 0]</text>\r\n",
       "<text text-anchor=\"start\" x=\"79.5\" y=\"-595.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M177.744,-698.907C170.049,-687.652 161.683,-675.418 153.949,-664.106\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.712,-661.946 148.178,-655.667 150.933,-665.897 156.712,-661.946\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"143.564\" y=\"-676.537\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<path fill=\"#ecfcf3\" stroke=\"black\" d=\"M357,-663C357,-663 216,-663 216,-663 210,-663 204,-657 204,-651 204,-651 204,-592 204,-592 204,-586 210,-580 216,-580 216,-580 357,-580 357,-580 363,-580 369,-586 369,-592 369,-592 369,-651 369,-651 369,-657 363,-663 357,-663\"/>\r\n",
       "<text text-anchor=\"start\" x=\"212\" y=\"-647.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) ≤ 4.75</text>\r\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-632.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.499</text>\r\n",
       "<text text-anchor=\"start\" x=\"243\" y=\"-617.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 78</text>\r\n",
       "<text text-anchor=\"start\" x=\"230\" y=\"-602.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 41, 37]</text>\r\n",
       "<text text-anchor=\"start\" x=\"231\" y=\"-587.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>0&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M233.603,-698.907C239.76,-690.014 246.34,-680.509 252.694,-671.331\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"255.633,-673.235 258.447,-663.021 249.877,-669.251 255.633,-673.235\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"262.919\" y=\"-683.918\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<path fill=\"#3ee684\" stroke=\"black\" d=\"M266,-544C266,-544 131,-544 131,-544 125,-544 119,-538 119,-532 119,-532 119,-473 119,-473 119,-467 125,-461 131,-461 131,-461 266,-461 266,-461 272,-461 278,-467 278,-473 278,-473 278,-532 278,-532 278,-538 272,-544 266,-544\"/>\r\n",
       "<text text-anchor=\"start\" x=\"127\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) ≤ 1.65</text>\r\n",
       "<text text-anchor=\"start\" x=\"161\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.053</text>\r\n",
       "<text text-anchor=\"start\" x=\"155\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 37</text>\r\n",
       "<text text-anchor=\"start\" x=\"146\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 36, 1]</text>\r\n",
       "<text text-anchor=\"start\" x=\"143\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M255.969,-579.907C249.211,-570.923 241.985,-561.315 235.016,-552.05\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"237.785,-549.909 228.977,-544.021 232.191,-554.116 237.785,-549.909\"/>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\r\n",
       "<path fill=\"#9254e9\" stroke=\"black\" d=\"M443,-544C443,-544 308,-544 308,-544 302,-544 296,-538 296,-532 296,-532 296,-473 296,-473 296,-467 302,-461 308,-461 308,-461 443,-461 443,-461 449,-461 455,-467 455,-473 455,-473 455,-532 455,-532 455,-538 449,-544 443,-544\"/>\r\n",
       "<text text-anchor=\"start\" x=\"304\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) ≤ 1.75</text>\r\n",
       "<text text-anchor=\"start\" x=\"338\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.214</text>\r\n",
       "<text text-anchor=\"start\" x=\"332\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 41</text>\r\n",
       "<text text-anchor=\"start\" x=\"323\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 5, 36]</text>\r\n",
       "<text text-anchor=\"start\" x=\"325.5\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;6 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>2&#45;&gt;6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M317.378,-579.907C324.212,-570.923 331.521,-561.315 338.569,-552.05\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"341.408,-554.099 344.676,-544.021 335.836,-549.861 341.408,-554.099\"/>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<path fill=\"#39e581\" stroke=\"black\" d=\"M115,-417.5C115,-417.5 12,-417.5 12,-417.5 6,-417.5 -7.10543e-015,-411.5 -7.10543e-015,-405.5 -7.10543e-015,-405.5 -7.10543e-015,-361.5 -7.10543e-015,-361.5 -7.10543e-015,-355.5 6,-349.5 12,-349.5 12,-349.5 115,-349.5 115,-349.5 121,-349.5 127,-355.5 127,-361.5 127,-361.5 127,-405.5 127,-405.5 127,-411.5 121,-417.5 115,-417.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"34.5\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"20\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 36</text>\r\n",
       "<text text-anchor=\"start\" x=\"11\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 36, 0]</text>\r\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M151.662,-460.907C138.039,-449.101 123.173,-436.217 109.596,-424.45\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"111.619,-421.571 101.77,-417.667 107.034,-426.861 111.619,-421.571\"/>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\r\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M249.5,-417.5C249.5,-417.5 157.5,-417.5 157.5,-417.5 151.5,-417.5 145.5,-411.5 145.5,-405.5 145.5,-405.5 145.5,-361.5 145.5,-361.5 145.5,-355.5 151.5,-349.5 157.5,-349.5 157.5,-349.5 249.5,-349.5 249.5,-349.5 255.5,-349.5 261.5,-355.5 261.5,-361.5 261.5,-361.5 261.5,-405.5 261.5,-405.5 261.5,-411.5 255.5,-417.5 249.5,-417.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"174.5\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"164\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"start\" x=\"155\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 1]</text>\r\n",
       "<text text-anchor=\"start\" x=\"153.5\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;5 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>3&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M200.235,-460.907C200.692,-450.204 201.187,-438.615 201.651,-427.776\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"205.152,-427.807 202.083,-417.667 198.159,-427.508 205.152,-427.807\"/>\r\n",
       "</g>\r\n",
       "<!-- 7 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>7</title>\r\n",
       "<path fill=\"#ffffff\" stroke=\"black\" d=\"M442,-425C442,-425 301,-425 301,-425 295,-425 289,-419 289,-413 289,-413 289,-354 289,-354 289,-348 295,-342 301,-342 301,-342 442,-342 442,-342 448,-342 454,-348 454,-354 454,-354 454,-413 454,-413 454,-419 448,-425 442,-425\"/>\r\n",
       "<text text-anchor=\"start\" x=\"297\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) ≤ 4.95</text>\r\n",
       "<text text-anchor=\"start\" x=\"342.5\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\r\n",
       "<text text-anchor=\"start\" x=\"332\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\r\n",
       "<text text-anchor=\"start\" x=\"323\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 4, 4]</text>\r\n",
       "<text text-anchor=\"start\" x=\"316\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 6&#45;&gt;7 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>6&#45;&gt;7</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M374.112,-460.907C373.827,-452.558 373.523,-443.671 373.227,-435.02\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"376.725,-434.895 372.885,-425.021 369.729,-435.135 376.725,-434.895\"/>\r\n",
       "</g>\r\n",
       "<!-- 14 -->\r\n",
       "<g id=\"node15\" class=\"node\"><title>14</title>\r\n",
       "<path fill=\"#853fe6\" stroke=\"black\" d=\"M625,-425C625,-425 484,-425 484,-425 478,-425 472,-419 472,-413 472,-413 472,-354 472,-354 472,-348 478,-342 484,-342 484,-342 625,-342 625,-342 631,-342 637,-348 637,-354 637,-354 637,-413 637,-413 637,-419 631,-425 625,-425\"/>\r\n",
       "<text text-anchor=\"start\" x=\"480\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) ≤ 4.85</text>\r\n",
       "<text text-anchor=\"start\" x=\"517\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.059</text>\r\n",
       "<text text-anchor=\"start\" x=\"511\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 33</text>\r\n",
       "<text text-anchor=\"start\" x=\"502\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 32]</text>\r\n",
       "<text text-anchor=\"start\" x=\"504.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 6&#45;&gt;14 -->\r\n",
       "<g id=\"edge14\" class=\"edge\"><title>6&#45;&gt;14</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M437.603,-460.907C452.598,-451.106 468.728,-440.563 484.074,-430.533\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"486.051,-433.422 492.507,-425.021 482.221,-427.562 486.051,-433.422\"/>\r\n",
       "</g>\r\n",
       "<!-- 8 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\r\n",
       "<path fill=\"#39e581\" stroke=\"black\" d=\"M262,-298.5C262,-298.5 159,-298.5 159,-298.5 153,-298.5 147,-292.5 147,-286.5 147,-286.5 147,-242.5 147,-242.5 147,-236.5 153,-230.5 159,-230.5 159,-230.5 262,-230.5 262,-230.5 268,-230.5 274,-236.5 274,-242.5 274,-242.5 274,-286.5 274,-286.5 274,-292.5 268,-298.5 262,-298.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"181.5\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"171\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\r\n",
       "<text text-anchor=\"start\" x=\"162\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2, 0]</text>\r\n",
       "<text text-anchor=\"start\" x=\"155\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 7&#45;&gt;8 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>7&#45;&gt;8</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M315.642,-341.907C299.091,-329.88 281.002,-316.735 264.567,-304.791\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"266.287,-301.714 256.14,-298.667 262.172,-307.377 266.287,-301.714\"/>\r\n",
       "</g>\r\n",
       "<!-- 9 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>9</title>\r\n",
       "<path fill=\"#c09cf2\" stroke=\"black\" d=\"M439,-306C439,-306 304,-306 304,-306 298,-306 292,-300 292,-294 292,-294 292,-235 292,-235 292,-229 298,-223 304,-223 304,-223 439,-223 439,-223 445,-223 451,-229 451,-235 451,-235 451,-294 451,-294 451,-300 445,-306 439,-306\"/>\r\n",
       "<text text-anchor=\"start\" x=\"300\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) ≤ 1.55</text>\r\n",
       "<text text-anchor=\"start\" x=\"334\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\r\n",
       "<text text-anchor=\"start\" x=\"332\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\r\n",
       "<text text-anchor=\"start\" x=\"323\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2, 4]</text>\r\n",
       "<text text-anchor=\"start\" x=\"321.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 7&#45;&gt;9 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>7&#45;&gt;9</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M371.5,-341.907C371.5,-333.649 371.5,-324.864 371.5,-316.302\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"375,-316.021 371.5,-306.021 368,-316.021 375,-316.021\"/>\r\n",
       "</g>\r\n",
       "<!-- 10 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>10</title>\r\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M264.5,-179.5C264.5,-179.5 172.5,-179.5 172.5,-179.5 166.5,-179.5 160.5,-173.5 160.5,-167.5 160.5,-167.5 160.5,-123.5 160.5,-123.5 160.5,-117.5 166.5,-111.5 172.5,-111.5 172.5,-111.5 264.5,-111.5 264.5,-111.5 270.5,-111.5 276.5,-117.5 276.5,-123.5 276.5,-123.5 276.5,-167.5 276.5,-167.5 276.5,-173.5 270.5,-179.5 264.5,-179.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"189.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"179\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\r\n",
       "<text text-anchor=\"start\" x=\"170\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 3]</text>\r\n",
       "<text text-anchor=\"start\" x=\"168.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 9&#45;&gt;10 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>9&#45;&gt;10</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M318.417,-222.907C302.689,-210.88 285.499,-197.735 269.88,-185.791\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"271.942,-182.961 261.872,-179.667 267.69,-188.522 271.942,-182.961\"/>\r\n",
       "</g>\r\n",
       "<!-- 11 -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>11</title>\r\n",
       "<path fill=\"#9cf2c0\" stroke=\"black\" d=\"M452,-187C452,-187 307,-187 307,-187 301,-187 295,-181 295,-175 295,-175 295,-116 295,-116 295,-110 301,-104 307,-104 307,-104 452,-104 452,-104 458,-104 464,-110 464,-116 464,-116 464,-175 464,-175 464,-181 458,-187 452,-187\"/>\r\n",
       "<text text-anchor=\"start\" x=\"303\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">sepal length (cm) ≤ 6.95</text>\r\n",
       "<text text-anchor=\"start\" x=\"342\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\r\n",
       "<text text-anchor=\"start\" x=\"340\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\r\n",
       "<text text-anchor=\"start\" x=\"331\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2, 1]</text>\r\n",
       "<text text-anchor=\"start\" x=\"324\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 9&#45;&gt;11 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>9&#45;&gt;11</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M374.276,-222.907C374.846,-214.558 375.454,-205.671 376.046,-197.02\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"379.539,-197.236 376.729,-187.021 372.555,-196.759 379.539,-197.236\"/>\r\n",
       "</g>\r\n",
       "<!-- 12 -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>12</title>\r\n",
       "<path fill=\"#39e581\" stroke=\"black\" d=\"M361,-68C361,-68 258,-68 258,-68 252,-68 246,-62 246,-56 246,-56 246,-12 246,-12 246,-6 252,-0 258,-0 258,-0 361,-0 361,-0 367,-0 373,-6 373,-12 373,-12 373,-56 373,-56 373,-62 367,-68 361,-68\"/>\r\n",
       "<text text-anchor=\"start\" x=\"280.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"270\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\r\n",
       "<text text-anchor=\"start\" x=\"261\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2, 0]</text>\r\n",
       "<text text-anchor=\"start\" x=\"254\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 11&#45;&gt;12 -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>11&#45;&gt;12</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M353.435,-103.726C347.837,-94.9703 341.913,-85.7032 336.289,-76.9051\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"339.123,-74.8399 330.787,-68.2996 333.225,-78.6103 339.123,-74.8399\"/>\r\n",
       "</g>\r\n",
       "<!-- 13 -->\r\n",
       "<g id=\"node14\" class=\"node\"><title>13</title>\r\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M495.5,-68C495.5,-68 403.5,-68 403.5,-68 397.5,-68 391.5,-62 391.5,-56 391.5,-56 391.5,-12 391.5,-12 391.5,-6 397.5,-0 403.5,-0 403.5,-0 495.5,-0 495.5,-0 501.5,-0 507.5,-6 507.5,-12 507.5,-12 507.5,-56 507.5,-56 507.5,-62 501.5,-68 495.5,-68\"/>\r\n",
       "<text text-anchor=\"start\" x=\"420.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"410\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"start\" x=\"401\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 1]</text>\r\n",
       "<text text-anchor=\"start\" x=\"399.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 11&#45;&gt;13 -->\r\n",
       "<g id=\"edge13\" class=\"edge\"><title>11&#45;&gt;13</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M405.565,-103.726C411.163,-94.9703 417.087,-85.7032 422.711,-76.9051\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"425.775,-78.6103 428.213,-68.2996 419.877,-74.8399 425.775,-78.6103\"/>\r\n",
       "</g>\r\n",
       "<!-- 15 -->\r\n",
       "<g id=\"node16\" class=\"node\"><title>15</title>\r\n",
       "<path fill=\"#c09cf2\" stroke=\"black\" d=\"M626,-306C626,-306 481,-306 481,-306 475,-306 469,-300 469,-294 469,-294 469,-235 469,-235 469,-229 475,-223 481,-223 481,-223 626,-223 626,-223 632,-223 638,-229 638,-235 638,-235 638,-294 638,-294 638,-300 632,-306 626,-306\"/>\r\n",
       "<text text-anchor=\"start\" x=\"477\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">sepal length (cm) ≤ 5.95</text>\r\n",
       "<text text-anchor=\"start\" x=\"516\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\r\n",
       "<text text-anchor=\"start\" x=\"514\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\r\n",
       "<text text-anchor=\"start\" x=\"505\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 2]</text>\r\n",
       "<text text-anchor=\"start\" x=\"503.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 14&#45;&gt;15 -->\r\n",
       "<g id=\"edge15\" class=\"edge\"><title>14&#45;&gt;15</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M554.153,-341.907C554.082,-333.649 554.007,-324.864 553.934,-316.302\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"557.432,-315.99 553.846,-306.021 550.432,-316.05 557.432,-315.99\"/>\r\n",
       "</g>\r\n",
       "<!-- 18 -->\r\n",
       "<g id=\"node19\" class=\"node\"><title>18</title>\r\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M765,-298.5C765,-298.5 668,-298.5 668,-298.5 662,-298.5 656,-292.5 656,-286.5 656,-286.5 656,-242.5 656,-242.5 656,-236.5 662,-230.5 668,-230.5 668,-230.5 765,-230.5 765,-230.5 771,-230.5 777,-236.5 777,-242.5 777,-242.5 777,-286.5 777,-286.5 777,-292.5 771,-298.5 765,-298.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"687.5\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"673\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 30</text>\r\n",
       "<text text-anchor=\"start\" x=\"664\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 30]</text>\r\n",
       "<text text-anchor=\"start\" x=\"666.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 14&#45;&gt;18 -->\r\n",
       "<g id=\"edge18\" class=\"edge\"><title>14&#45;&gt;18</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M610.705,-341.907C627.359,-329.88 645.56,-316.735 662.097,-304.791\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"664.519,-307.359 670.577,-298.667 660.421,-301.684 664.519,-307.359\"/>\r\n",
       "</g>\r\n",
       "<!-- 16 -->\r\n",
       "<g id=\"node17\" class=\"node\"><title>16</title>\r\n",
       "<path fill=\"#39e581\" stroke=\"black\" d=\"M601,-179.5C601,-179.5 498,-179.5 498,-179.5 492,-179.5 486,-173.5 486,-167.5 486,-167.5 486,-123.5 486,-123.5 486,-117.5 492,-111.5 498,-111.5 498,-111.5 601,-111.5 601,-111.5 607,-111.5 613,-117.5 613,-123.5 613,-123.5 613,-167.5 613,-167.5 613,-173.5 607,-179.5 601,-179.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"520.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"510\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"start\" x=\"501\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 0]</text>\r\n",
       "<text text-anchor=\"start\" x=\"494\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 15&#45;&gt;16 -->\r\n",
       "<g id=\"edge16\" class=\"edge\"><title>15&#45;&gt;16</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M552.112,-222.907C551.746,-212.204 551.35,-200.615 550.98,-189.776\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"554.474,-189.541 550.634,-179.667 547.478,-189.781 554.474,-189.541\"/>\r\n",
       "</g>\r\n",
       "<!-- 17 -->\r\n",
       "<g id=\"node18\" class=\"node\"><title>17</title>\r\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M735.5,-179.5C735.5,-179.5 643.5,-179.5 643.5,-179.5 637.5,-179.5 631.5,-173.5 631.5,-167.5 631.5,-167.5 631.5,-123.5 631.5,-123.5 631.5,-117.5 637.5,-111.5 643.5,-111.5 643.5,-111.5 735.5,-111.5 735.5,-111.5 741.5,-111.5 747.5,-117.5 747.5,-123.5 747.5,-123.5 747.5,-167.5 747.5,-167.5 747.5,-173.5 741.5,-179.5 735.5,-179.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"660.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"650\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\r\n",
       "<text text-anchor=\"start\" x=\"641\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 2]</text>\r\n",
       "<text text-anchor=\"start\" x=\"639.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 15&#45;&gt;17 -->\r\n",
       "<g id=\"edge17\" class=\"edge\"><title>15&#45;&gt;17</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M600.685,-222.907C614.409,-211.101 629.385,-198.217 643.063,-186.45\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"645.649,-188.842 650.947,-179.667 641.084,-183.535 645.649,-188.842\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x16e10118b38>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                      feature_names=iris.feature_names,  \n",
    "                      class_names=iris.target_names,  \n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to export your tree into images or pdf, you can use Graphviz render "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'res/graphviz\\\\tree1.png'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.format = 'png'\n",
    "# graph.format = 'pdf'\n",
    "graph.render('res/graphviz/tree1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree can also used to estimate the value of continuous variable. However, regression models and neural networks are usually works better. These are a simple example of using a `DecisionTreeRegressor`. We will not focus on this one since we're on classification course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "X = [[0, 0], [2, 2]]\n",
    "y = [0.5, 2.5]\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "clf = clf.fit(X, y)\n",
    "clf.predict([[1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Create the sample data\n",
    "rng = np.random.RandomState(1)\n",
    "X = np.linspace(0, 6, 100)[:, np.newaxis]\n",
    "y = np.sin(X).ravel() + np.sin(11 * X).ravel() + rng.normal(0, 0.1, X.shape[0])\n",
    "\n",
    "# Fit regression model\n",
    "regr_1 = DecisionTreeRegressor(max_depth=4)\n",
    "regr_1.fit(X, y)\n",
    "\n",
    "# Predict\n",
    "y_1 = regr_1.predict(X)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure()\n",
    "plt.scatter(X, y, c=\"k\", label=\"training samples\")\n",
    "plt.plot(X, y_1, c=\"g\", label=\"n_tree=1\", linewidth=2)\n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"target\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune your Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most Machine Learning workflow, we should (and we must!) tune our model to fit into our validation data (Remember, validation is not test data). The easiest way to tune our model (tree) is by changing its hyperparameter. To put it simple, hyperparameters is **list of parameters we set for our model**. It could be anything (depends on how the developer build it). A change in hyperparameter changes the model, and its performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters vs Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is true that the term `parameter` and `hyperparameter` used interchangeably in several webs, course, or even classes. But sometimes they don't gives a clear differences between the two. I think it's necessary to know the differents that Parameter are what the model learn while Hyperparameters are what the model can't learn, hence we set it beforehand. \n",
    "\n",
    "The easiest example is Linear Regression. You set the hyperparameter as Number of Iterations(epoch), Wich resulting the model : $y = MX+b$. \n",
    "If you're aware of how the regression works, the algorithm will gradually change the $M$ so that the $MX+b$ will fit the data. In other word, the model learns to find the best $M$. So, the $M$ in our model is the model's parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look on our `DecisionTreeClassifier` hyperparameters. We can use the built-in function to call the self-read documentation of each objects provided by its developer using `help`. However, it's recomended for you to jump into its [documentation page](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) or community page if available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DecisionTreeClassifier in module sklearn.tree.tree:\n",
      "\n",
      "class DecisionTreeClassifier(BaseDecisionTree, sklearn.base.ClassifierMixin)\n",
      " |  DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort=False)\n",
      " |  \n",
      " |  A decision tree classifier.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <tree>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  criterion : string, optional (default=\"gini\")\n",
      " |      The function to measure the quality of a split. Supported criteria are\n",
      " |      \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
      " |  \n",
      " |  splitter : string, optional (default=\"best\")\n",
      " |      The strategy used to choose the split at each node. Supported\n",
      " |      strategies are \"best\" to choose the best split and \"random\" to choose\n",
      " |      the best random split.\n",
      " |  \n",
      " |  max_depth : int or None, optional (default=None)\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int, float, optional (default=2)\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a fraction and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int, float, optional (default=1)\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a fraction and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, optional (default=0.)\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_features : int, float, string or None, optional (default=None)\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |          - If int, then consider `max_features` features at each split.\n",
      " |          - If float, then `max_features` is a fraction and\n",
      " |            `int(max_features * n_features)` features are considered at each\n",
      " |            split.\n",
      " |          - If \"auto\", then `max_features=sqrt(n_features)`.\n",
      " |          - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      " |          - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |          - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default=None)\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`.\n",
      " |  \n",
      " |  max_leaf_nodes : int or None, optional (default=None)\n",
      " |      Grow a tree with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_decrease : float, optional (default=0.)\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  min_impurity_split : float, (default=1e-7)\n",
      " |      Threshold for early stopping in tree growth. A node will split\n",
      " |      if its impurity is above the threshold, otherwise it is a leaf.\n",
      " |  \n",
      " |      .. deprecated:: 0.19\n",
      " |         ``min_impurity_split`` has been deprecated in favor of\n",
      " |         ``min_impurity_decrease`` in 0.19. The default value of\n",
      " |         ``min_impurity_split`` will change from 1e-7 to 0 in 0.23 and it\n",
      " |         will be removed in 0.25. Use ``min_impurity_decrease`` instead.\n",
      " |  \n",
      " |  class_weight : dict, list of dicts, \"balanced\" or None, default=None\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one. For\n",
      " |      multi-output problems, a list of dicts can be provided in the same\n",
      " |      order as the columns of y.\n",
      " |  \n",
      " |      Note that for multioutput (including multilabel) weights should be\n",
      " |      defined for each class of every column in its own dict. For example,\n",
      " |      for four-class multilabel classification weights should be\n",
      " |      [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
      " |      [{1:1}, {2:5}, {3:1}, {4:1}].\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |      For multi-output, the weights of each column of y will be multiplied.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |  presort : bool, optional (default=False)\n",
      " |      Whether to presort the data to speed up the finding of best splits in\n",
      " |      fitting. For the default settings of a decision tree on large\n",
      " |      datasets, setting this to true may slow down the training process.\n",
      " |      When using either a smaller dataset or a restricted depth, this may\n",
      " |      speed up the training.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  classes_ : array of shape = [n_classes] or a list of such arrays\n",
      " |      The classes labels (single output problem),\n",
      " |      or a list of arrays of class labels (multi-output problem).\n",
      " |  \n",
      " |  feature_importances_ : array of shape = [n_features]\n",
      " |      The feature importances. The higher, the more important the\n",
      " |      feature. The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance [4]_.\n",
      " |  \n",
      " |  max_features_ : int,\n",
      " |      The inferred value of max_features.\n",
      " |  \n",
      " |  n_classes_ : int or list\n",
      " |      The number of classes (for single output problems),\n",
      " |      or a list containing the number of classes for each\n",
      " |      output (for multi-output problems).\n",
      " |  \n",
      " |  n_features_ : int\n",
      " |      The number of features when ``fit`` is performed.\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  tree_ : Tree object\n",
      " |      The underlying Tree object. Please refer to\n",
      " |      ``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n",
      " |      :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\n",
      " |      for basic usage of these attributes.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default values for the parameters controlling the size of the trees\n",
      " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      " |  unpruned trees which can potentially be very large on some data sets. To\n",
      " |  reduce memory consumption, the complexity and size of the trees should be\n",
      " |  controlled by setting those parameter values.\n",
      " |  \n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data and\n",
      " |  ``max_features=n_features``, if the improvement of the criterion is\n",
      " |  identical for several splits enumerated during the search of the best\n",
      " |  split. To obtain a deterministic behaviour during fitting,\n",
      " |  ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  DecisionTreeRegressor\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  .. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n",
      " |  \n",
      " |  .. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, \"Classification\n",
      " |         and Regression Trees\", Wadsworth, Belmont, CA, 1984.\n",
      " |  \n",
      " |  .. [3] T. Hastie, R. Tibshirani and J. Friedman. \"Elements of Statistical\n",
      " |         Learning\", Springer, 2009.\n",
      " |  \n",
      " |  .. [4] L. Breiman, and A. Cutler, \"Random Forests\",\n",
      " |         https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import load_iris\n",
      " |  >>> from sklearn.model_selection import cross_val_score\n",
      " |  >>> from sklearn.tree import DecisionTreeClassifier\n",
      " |  >>> clf = DecisionTreeClassifier(random_state=0)\n",
      " |  >>> iris = load_iris()\n",
      " |  >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
      " |  ...                             # doctest: +SKIP\n",
      " |  ...\n",
      " |  array([ 1.     ,  0.93...,  0.86...,  0.93...,  0.93...,\n",
      " |          0.93...,  0.93...,  1.     ,  0.93...,  1.      ])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DecisionTreeClassifier\n",
      " |      BaseDecisionTree\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      " |      Build a decision tree classifier from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The training input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples] or [n_samples, n_outputs]\n",
      " |          The target values (class labels) as integers or strings.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples] or None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. Splits are also\n",
      " |          ignored if they would result in any single class carrying a\n",
      " |          negative weight in either child node.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      X_idx_sorted : array-like, shape = [n_samples, n_features], optional\n",
      " |          The indexes of the sorted training input samples. If many tree\n",
      " |          are grown on the same dataset, this allows the ordering to be\n",
      " |          cached between trees. If None, the data will be sorted here.\n",
      " |          Don't use this parameter unless you know what to do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict class log-probabilities of the input samples X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape = [n_samples, n_classes], or a list of n_outputs\n",
      " |          such arrays if n_outputs > 1.\n",
      " |          The class log-probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X, check_input=True)\n",
      " |      Predict class probabilities of the input samples X.\n",
      " |      \n",
      " |      The predicted class probability is the fraction of samples of the same\n",
      " |      class in a leaf.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : bool\n",
      " |          Run check_array on X.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape = [n_samples, n_classes], or a list of n_outputs\n",
      " |          such arrays if n_outputs > 1.\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseDecisionTree:\n",
      " |  \n",
      " |  apply(self, X, check_input=True)\n",
      " |      Returns the index of the leaf that each sample is predicted as.\n",
      " |      \n",
      " |      .. versionadded:: 0.17\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array_like, shape = [n_samples,]\n",
      " |          For each datapoint x in X, return the index of the leaf x\n",
      " |          ends up in. Leaves are numbered within\n",
      " |          ``[0; self.tree_.node_count)``, possibly with gaps in the\n",
      " |          numbering.\n",
      " |  \n",
      " |  decision_path(self, X, check_input=True)\n",
      " |      Return the decision path in the tree\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse csr array, shape = [n_samples, n_nodes]\n",
      " |          Return a node indicator matrix where non zero elements\n",
      " |          indicates that the samples goes through the nodes.\n",
      " |  \n",
      " |  get_depth(self)\n",
      " |      Returns the depth of the decision tree.\n",
      " |      \n",
      " |      The depth of a tree is the maximum distance between the root\n",
      " |      and any leaf.\n",
      " |  \n",
      " |  get_n_leaves(self)\n",
      " |      Returns the number of leaves of the decision tree.\n",
      " |  \n",
      " |  predict(self, X, check_input=True)\n",
      " |      Predict class or regression value for X.\n",
      " |      \n",
      " |      For a classification model, the predicted class for each sample in X is\n",
      " |      returned. For a regression model, the predicted value based on X is\n",
      " |      returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array of shape = [n_samples] or [n_samples, n_outputs]\n",
      " |          The predicted classes, or the predict values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseDecisionTree:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Return the feature importances.\n",
      " |      \n",
      " |      The importance of a feature is computed as the (normalized) total\n",
      " |      reduction of the criterion brought by that feature.\n",
      " |      It is also known as the Gini importance.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : array, shape = [n_features]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tree.DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the list of hyperparameters showed before, let's inspect and fine-tune : \n",
    "- max_depth\n",
    "- min_samples_split\n",
    "- min_smples_leaf\n",
    "\n",
    "To tune, is by mean, do a search in order to find the value wich resulting in best performance of our models. There are lots of optimization field of study (especially in continuous space problem) like [Swarm Intelligence](https://en.wikipedia.org/wiki/Swarm_intelligence), [Evolutionary Computation](https://en.wikipedia.org/wiki/Evolutionary_computation), etc to do this job. We will not focus on the algorithm, so let's just inspect and do a exhaustive search, Grid Search! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "param_grid = {'max_depth': np.arange(3, 10),\n",
    "              'min_samples_split' : np.arange(2, 10),\n",
    "              'min_samples_leaf' : np.arange(2, 10),\n",
    "             }\n",
    "\n",
    "clf = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=7) # Grid Search on 7-fold Cross Validaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dzul\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=7, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': array([3, 4, 5, 6, 7, 8, 9]),\n",
       "                         'min_samples_leaf': array([2, 3, 4, 5, 6, 7, 8, 9]),\n",
       "                         'min_samples_split': array([2, 3, 4, 5, 6, 7, 8, 9])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(titanic.loc[:,titanic.columns != 'Survived'], titanic['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9, 'min_samples_leaf': 3, 'min_samples_split': 5}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used more than 2 feature, so it's unlikely to visualize the process. But you can see the process in the `cv_results_`, and focus on `params` and `std_test_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00356429, 0.00313629, 0.00299808, 0.00285203, 0.00199332,\n",
       "        0.00227969, 0.0024223 , 0.00227867, 0.00242141, 0.00228136,\n",
       "        0.00242012, 0.00228003, 0.00228892, 0.00227853, 0.00241106,\n",
       "        0.00215387, 0.0027084 , 0.00284583, 0.00285622, 0.00241511,\n",
       "        0.00329348, 0.0027006 , 0.00241872, 0.0032803 , 0.00269525,\n",
       "        0.00299495, 0.00229154, 0.00214417, 0.00227652, 0.00298132,\n",
       "        0.00313514, 0.00299542, 0.00255833, 0.004271  , 0.00198048,\n",
       "        0.00342536, 0.00299389, 0.002424  , 0.00199311, 0.00201641,\n",
       "        0.00213718, 0.00214413, 0.00199338, 0.00199372, 0.00213524,\n",
       "        0.00198718, 0.00213569, 0.00199897, 0.00213524, 0.00199941,\n",
       "        0.00214362, 0.00213804, 0.00227652, 0.00186171, 0.00156696,\n",
       "        0.00213586, 0.00200803, 0.00313398, 0.00299239, 0.00313459,\n",
       "        0.00384368, 0.0031288 , 0.00256511, 0.00285271, 0.00356899,\n",
       "        0.00228078, 0.00299713, 0.00227315, 0.00227359, 0.00215384,\n",
       "        0.00242877, 0.00213926, 0.00213746, 0.00214294, 0.00257083,\n",
       "        0.00297434, 0.00256024, 0.00256293, 0.0029801 , 0.00242077,\n",
       "        0.0035662 , 0.00283882, 0.00356708, 0.00256205, 0.00270711,\n",
       "        0.00227915, 0.00227976, 0.00227945, 0.0024241 , 0.00199413,\n",
       "        0.00199263, 0.00242472, 0.00213698, 0.00199716, 0.00213729,\n",
       "        0.00199481, 0.00242206, 0.00213725, 0.00214199, 0.00227874,\n",
       "        0.00242785, 0.00227846, 0.00213661, 0.0019927 , 0.00227962,\n",
       "        0.00227962, 0.0031288 , 0.00284614, 0.002277  , 0.00242172,\n",
       "        0.00242117, 0.00284972, 0.00227073, 0.00256378, 0.00270387,\n",
       "        0.00256406, 0.00285547, 0.00299879, 0.00269839, 0.00256399,\n",
       "        0.00214488, 0.00228657, 0.00214672, 0.00242628, 0.00212639,\n",
       "        0.00214001, 0.00213218, 0.00227952, 0.00213715, 0.00242645,\n",
       "        0.00242632, 0.00270108, 0.00242005, 0.00242281, 0.00255636,\n",
       "        0.00227911, 0.00228013, 0.00213841, 0.00227915, 0.00270247,\n",
       "        0.00227806, 0.00227754, 0.00257611, 0.00212557, 0.00227124,\n",
       "        0.00227979, 0.00256722, 0.00213708, 0.00228163, 0.00213671,\n",
       "        0.00229662, 0.00227989, 0.00228245, 0.00228248, 0.00242169,\n",
       "        0.00213718, 0.00228133, 0.00255758, 0.0024147 , 0.00213044,\n",
       "        0.00284736, 0.00228568, 0.00228538, 0.00242833, 0.00256991,\n",
       "        0.00200391, 0.00228034, 0.00213746, 0.00213858, 0.00227955,\n",
       "        0.00213099, 0.00242107, 0.00256021, 0.0021459 , 0.00214086,\n",
       "        0.00227789, 0.00241474, 0.00213419, 0.00227206, 0.00240438,\n",
       "        0.00270568, 0.00242216, 0.00270271, 0.00256235, 0.0024116 ,\n",
       "        0.00213586, 0.00227445, 0.00227826, 0.00242407, 0.00242897,\n",
       "        0.00242649, 0.00242819, 0.00255779, 0.00256641, 0.00299777,\n",
       "        0.00286453, 0.00284682, 0.00284832, 0.00256641, 0.00314007,\n",
       "        0.00241525, 0.00269628, 0.00269852, 0.00284008, 0.00284668,\n",
       "        0.00256511, 0.00256208, 0.00242288, 0.00242233, 0.00242489,\n",
       "        0.00242809, 0.00242863, 0.00242233, 0.00242203, 0.00256753,\n",
       "        0.0024114 , 0.00212489, 0.00227969, 0.00412893, 0.00241974,\n",
       "        0.00284972, 0.00241521, 0.00284072, 0.00298977, 0.00299961,\n",
       "        0.00256923, 0.0029945 , 0.00270816, 0.00228623, 0.00283558,\n",
       "        0.00242087, 0.00255305, 0.00228017, 0.00256119, 0.00255738,\n",
       "        0.00270837, 0.00270666, 0.00227799, 0.00242087, 0.00213548,\n",
       "        0.00256463, 0.00227966, 0.00242216, 0.00227942, 0.00199454,\n",
       "        0.00242424, 0.00242203, 0.00228156, 0.00213453, 0.00213715,\n",
       "        0.0024237 , 0.00214876, 0.00242809, 0.00213752, 0.00242359,\n",
       "        0.00256337, 0.00270687, 0.00242795, 0.00256256, 0.00242826,\n",
       "        0.00227935, 0.00256371, 0.00241685, 0.00257461, 0.00242458,\n",
       "        0.00228347, 0.00227993, 0.00227765, 0.00270639, 0.00241627,\n",
       "        0.00242458, 0.00228303, 0.00242461, 0.00242315, 0.00214342,\n",
       "        0.00284198, 0.00285111, 0.0024222 , 0.00227972, 0.00227744,\n",
       "        0.00227744, 0.00242226, 0.00227959, 0.00242506, 0.00227949,\n",
       "        0.00228126, 0.00270823, 0.00227979, 0.00242271, 0.00227966,\n",
       "        0.00242237, 0.00228051, 0.0024222 , 0.00241988, 0.00256463,\n",
       "        0.00284951, 0.0024223 , 0.00242373, 0.00242199, 0.00227979,\n",
       "        0.00228027, 0.00213718, 0.00241913, 0.00213712, 0.00227949,\n",
       "        0.00228211, 0.00228047, 0.00228143, 0.00242356, 0.00242301,\n",
       "        0.00227959, 0.00242203, 0.00227945, 0.00213064, 0.00227966,\n",
       "        0.00213848, 0.0028504 , 0.00241705, 0.00256961, 0.00242162,\n",
       "        0.00228299, 0.00270721, 0.00269825, 0.00241814, 0.00228092,\n",
       "        0.00256593, 0.0025648 , 0.00256433, 0.00257301, 0.00242308,\n",
       "        0.00256566, 0.00228006, 0.00242288, 0.00256974, 0.00241869,\n",
       "        0.00255936, 0.0025676 , 0.00255854, 0.00284702, 0.00271245,\n",
       "        0.00256365, 0.00242158, 0.00228466, 0.00243098, 0.00242788,\n",
       "        0.00241082, 0.0028366 , 0.00283064, 0.00256085, 0.00242352,\n",
       "        0.00242036, 0.00227955, 0.00257019, 0.00256126, 0.00227509,\n",
       "        0.0027208 , 0.00242172, 0.00241634, 0.00213913, 0.0027067 ,\n",
       "        0.0024255 , 0.0022802 , 0.00214219, 0.00242271, 0.00213565,\n",
       "        0.00214011, 0.00242257, 0.00242608, 0.00214274, 0.0024271 ,\n",
       "        0.00227945, 0.00241961, 0.00213732, 0.00270707, 0.00256436,\n",
       "        0.00227802, 0.00227962, 0.0024222 , 0.0022819 , 0.00256467,\n",
       "        0.00227966, 0.00242203, 0.00242186, 0.00213718, 0.0027069 ,\n",
       "        0.00228184, 0.0025662 , 0.00241988, 0.002707  , 0.00242162,\n",
       "        0.00242216, 0.00285077, 0.00284634, 0.00284454, 0.00441681,\n",
       "        0.00299382, 0.00313493, 0.00327713, 0.00270384, 0.00284607,\n",
       "        0.00328118, 0.00284512, 0.00284869, 0.00284324, 0.00256467,\n",
       "        0.0022849 , 0.00270629, 0.00242117, 0.00242404, 0.00242863,\n",
       "        0.00271205, 0.00285176, 0.00241934, 0.00256835, 0.00256334,\n",
       "        0.00227707, 0.00256491, 0.00241429, 0.0025597 , 0.00270166,\n",
       "        0.0022753 , 0.00227053, 0.00242261, 0.00242349, 0.00255854,\n",
       "        0.00214805, 0.00228483, 0.00255823, 0.00256542, 0.00227247,\n",
       "        0.00270901, 0.00256572, 0.00241031, 0.00242632, 0.00242209,\n",
       "        0.00242608, 0.00256508, 0.00213565, 0.00228184, 0.00242836,\n",
       "        0.00255857, 0.00256334, 0.00256099, 0.0021365 , 0.00228586,\n",
       "        0.00257642, 0.00256327, 0.00213633]),\n",
       " 'std_fit_time': array([1.67280438e-03, 1.79267226e-03, 1.06018003e-03, 3.50586734e-04,\n",
       "        2.88605284e-06, 4.50751886e-04, 4.93646121e-04, 6.97164333e-04,\n",
       "        4.94024508e-04, 4.49488820e-04, 4.91420141e-04, 4.51140288e-04,\n",
       "        4.50547836e-04, 4.49522362e-04, 5.08419136e-04, 3.43949426e-04,\n",
       "        6.84757115e-04, 3.48229290e-04, 1.35108732e-03, 7.10778880e-04,\n",
       "        1.28292516e-03, 8.73606346e-04, 4.89025366e-04, 1.16921570e-03,\n",
       "        1.03441103e-03, 1.41188657e-03, 1.15480991e-03, 3.31869602e-04,\n",
       "        6.93343398e-04, 1.30751851e-03, 1.35263689e-03, 1.31000707e-03,\n",
       "        4.77524991e-04, 2.04927875e-03, 1.64529621e-05, 1.67635842e-03,\n",
       "        1.31354453e-03, 7.16881358e-04, 2.05110122e-05, 5.31702876e-04,\n",
       "        3.34197807e-04, 3.52550325e-04, 1.67344209e-06, 1.13769919e-05,\n",
       "        3.50847256e-04, 5.26278178e-04, 3.38791296e-04, 1.00796285e-05,\n",
       "        3.50018854e-04, 1.46058958e-05, 3.42328851e-04, 3.44863503e-04,\n",
       "        4.48964909e-04, 3.53149941e-04, 4.92895006e-04, 3.49125307e-04,\n",
       "        1.76202756e-05, 1.71169955e-03, 1.68740071e-03, 1.24500354e-03,\n",
       "        1.95199571e-03, 1.23676566e-03, 7.26569338e-04, 1.35691388e-03,\n",
       "        1.28772575e-03, 7.04300494e-04, 1.31279035e-03, 4.54811541e-04,\n",
       "        4.46688689e-04, 3.69309454e-04, 5.02530667e-04, 3.47257592e-04,\n",
       "        3.51562598e-04, 3.61404065e-04, 4.98415450e-04, 9.23985955e-04,\n",
       "        1.04796666e-03, 7.13892463e-04, 5.42139687e-04, 4.84333545e-04,\n",
       "        1.17006692e-03, 9.78912646e-04, 1.40192529e-03, 1.04644732e-03,\n",
       "        6.98269203e-04, 4.50946953e-04, 4.50784192e-04, 4.50525681e-04,\n",
       "        4.96025810e-04, 1.46971083e-06, 4.93855312e-06, 7.25285586e-04,\n",
       "        3.48928419e-04, 5.77672633e-06, 3.48900617e-04, 5.33145639e-04,\n",
       "        4.93577290e-04, 3.49011849e-04, 3.47166467e-04, 4.51132103e-04,\n",
       "        5.01726078e-04, 4.44887003e-04, 3.47816109e-04, 5.29394820e-04,\n",
       "        4.50644251e-04, 4.50493365e-04, 9.85774052e-04, 1.34662777e-03,\n",
       "        4.49075751e-04, 7.26700375e-04, 7.29034799e-04, 1.34875548e-03,\n",
       "        4.45040659e-04, 1.04529757e-03, 8.74815236e-04, 1.04576557e-03,\n",
       "        1.35073362e-03, 1.60842814e-03, 6.94576058e-04, 4.92344805e-04,\n",
       "        3.59841641e-04, 4.56552501e-04, 3.56817986e-04, 4.90308785e-04,\n",
       "        3.41482417e-04, 3.57834289e-04, 3.32310784e-04, 4.47727493e-04,\n",
       "        3.47166069e-04, 4.91747845e-04, 4.97593189e-04, 6.90393969e-04,\n",
       "        4.91840727e-04, 4.92594067e-04, 4.85964484e-04, 4.49690717e-04,\n",
       "        4.50189492e-04, 3.48155866e-04, 4.50363543e-04, 6.85258915e-04,\n",
       "        4.61127357e-04, 4.43465950e-04, 5.02922730e-04, 3.53970805e-04,\n",
       "        4.37738435e-04, 4.52279594e-04, 4.97235352e-04, 3.47235824e-04,\n",
       "        4.52398402e-04, 3.49534345e-04, 4.53839550e-04, 4.52135691e-04,\n",
       "        4.64872818e-04, 4.51483154e-04, 4.92808405e-04, 3.49046428e-04,\n",
       "        4.50173943e-04, 7.06167184e-04, 4.84435056e-04, 3.34284122e-04,\n",
       "        6.33987053e-04, 4.47100860e-04, 4.48085954e-04, 4.99564368e-04,\n",
       "        4.98492990e-04, 1.45192245e-05, 4.50279511e-04, 3.31849358e-04,\n",
       "        3.51980729e-04, 4.49951140e-04, 3.51667670e-04, 7.10581512e-04,\n",
       "        7.28273221e-04, 3.45588153e-04, 3.43653184e-04, 4.64819689e-04,\n",
       "        4.84687245e-04, 3.44524873e-04, 4.54662520e-04, 4.82435262e-04,\n",
       "        6.83312459e-04, 4.94221738e-04, 6.96696527e-04, 7.17810900e-04,\n",
       "        4.82650756e-04, 3.47950819e-04, 4.42412488e-04, 4.50689098e-04,\n",
       "        4.92872171e-04, 4.99168837e-04, 4.98965941e-04, 4.89024227e-04,\n",
       "        4.85536000e-04, 4.90311598e-04, 1.06484972e-03, 6.35110256e-04,\n",
       "        6.31263488e-04, 6.37225073e-04, 4.95221318e-04, 9.89495150e-04,\n",
       "        7.18340079e-04, 4.42146504e-04, 4.44769713e-04, 3.45868402e-04,\n",
       "        3.48036262e-04, 4.96650409e-04, 4.91824507e-04, 7.13732627e-04,\n",
       "        4.94259303e-04, 4.86425585e-04, 5.03045307e-04, 4.87808622e-04,\n",
       "        4.92955190e-04, 4.95196015e-04, 4.81681383e-04, 4.83311088e-04,\n",
       "        3.35226305e-04, 4.50807064e-04, 1.62961298e-03, 5.01437479e-04,\n",
       "        9.93654361e-04, 1.06186139e-03, 1.11545606e-03, 1.40522506e-03,\n",
       "        1.07337221e-03, 7.29788710e-04, 1.31371985e-03, 8.74117033e-04,\n",
       "        4.47809491e-04, 3.42444442e-04, 7.25046590e-04, 7.13378790e-04,\n",
       "        4.43589846e-04, 4.91704365e-04, 4.97479953e-04, 4.50516597e-04,\n",
       "        6.98281414e-04, 4.47919775e-04, 4.94687707e-04, 3.44868273e-04,\n",
       "        4.93655991e-04, 4.50471860e-04, 4.93695293e-04, 4.50547691e-04,\n",
       "        1.66858247e-07, 7.28024674e-04, 4.93606825e-04, 4.53425752e-04,\n",
       "        3.50079541e-04, 3.48956299e-04, 4.93817012e-04, 3.47366223e-04,\n",
       "        4.98032818e-04, 3.49295874e-04, 4.93927604e-04, 4.92773786e-04,\n",
       "        4.51010714e-04, 4.90945015e-04, 4.95315247e-04, 4.90941683e-04,\n",
       "        6.99317670e-04, 4.96152983e-04, 4.89033130e-04, 4.94085606e-04,\n",
       "        4.95695315e-04, 4.45766618e-04, 4.49401733e-04, 4.53034439e-04,\n",
       "        4.50487957e-04, 4.85355597e-04, 5.03133784e-04, 4.47031352e-04,\n",
       "        4.95247425e-04, 4.85396921e-04, 3.48056071e-04, 6.38163473e-04,\n",
       "        9.87427643e-04, 4.93459303e-04, 4.50579620e-04, 4.46842210e-04,\n",
       "        4.51824491e-04, 4.93537955e-04, 4.50514957e-04, 4.97149690e-04,\n",
       "        4.50730334e-04, 4.53315255e-04, 6.99944597e-04, 4.50611861e-04,\n",
       "        7.26302153e-04, 4.50622627e-04, 4.93793952e-04, 4.52123614e-04,\n",
       "        7.26742055e-04, 4.95629501e-04, 7.26454826e-04, 8.30432879e-04,\n",
       "        4.94059337e-04, 4.95379362e-04, 4.93773978e-04, 4.50536473e-04,\n",
       "        4.50086909e-04, 3.48942396e-04, 4.90031310e-04, 3.49067522e-04,\n",
       "        4.50428748e-04, 4.54597962e-04, 4.50034216e-04, 4.49445338e-04,\n",
       "        7.29776793e-04, 4.94612683e-04, 4.50590331e-04, 4.93469158e-04,\n",
       "        4.50676485e-04, 3.51850179e-04, 4.50698037e-04, 3.48524135e-04,\n",
       "        6.37215071e-04, 4.88945005e-04, 4.99370427e-04, 4.91073140e-04,\n",
       "        4.57165440e-04, 4.49937424e-04, 6.88407258e-04, 4.84365869e-04,\n",
       "        4.49093211e-04, 4.94582790e-04, 4.93873744e-04, 4.94880672e-04,\n",
       "        4.89613535e-04, 4.92173028e-04, 4.92289912e-04, 4.49765669e-04,\n",
       "        4.91986820e-04, 4.97589860e-04, 4.88342925e-04, 7.06843173e-04,\n",
       "        4.94861372e-04, 4.89543518e-04, 6.28753554e-04, 7.01323726e-04,\n",
       "        4.92870606e-04, 4.92768572e-04, 4.48791402e-04, 4.88518708e-04,\n",
       "        4.99693243e-04, 4.81694696e-04, 3.44686149e-04, 6.21443436e-04,\n",
       "        4.90347905e-04, 4.81757493e-04, 4.95125202e-04, 4.49047064e-04,\n",
       "        4.97274492e-04, 4.88933866e-04, 4.40178515e-04, 6.85028666e-04,\n",
       "        4.93054148e-04, 4.86485508e-04, 3.50591545e-04, 6.82835588e-04,\n",
       "        4.90240907e-04, 4.48935744e-04, 3.45266560e-04, 4.92767722e-04,\n",
       "        3.49002615e-04, 3.50008258e-04, 4.94512730e-04, 4.99761004e-04,\n",
       "        3.47895873e-04, 4.99781060e-04, 4.50450351e-04, 4.90839194e-04,\n",
       "        3.48789394e-04, 4.50374936e-04, 4.93217186e-04, 6.98407101e-04,\n",
       "        4.50493383e-04, 7.26695313e-04, 7.03530007e-04, 4.93547816e-04,\n",
       "        4.50471824e-04, 4.93538005e-04, 4.93832754e-04, 3.49137010e-04,\n",
       "        4.50568796e-04, 4.54315465e-04, 4.95165434e-04, 4.91012956e-04,\n",
       "        4.50558093e-04, 4.92861021e-04, 4.93419985e-04, 6.39160680e-04,\n",
       "        6.35153115e-04, 6.38001186e-04, 1.39773017e-03, 5.29412690e-04,\n",
       "        1.35218033e-03, 1.02712812e-03, 6.91940052e-04, 6.37843521e-04,\n",
       "        1.27778525e-03, 9.83757072e-04, 9.95356468e-04, 6.36519024e-04,\n",
       "        4.92183498e-04, 4.59406466e-04, 4.50117283e-04, 4.93459806e-04,\n",
       "        4.92904886e-04, 4.88594321e-04, 4.43338918e-04, 9.92661943e-04,\n",
       "        4.88828974e-04, 4.94323191e-04, 4.97014229e-04, 4.40881453e-04,\n",
       "        7.30030726e-04, 4.89744058e-04, 7.13264434e-04, 6.96563999e-04,\n",
       "        4.42741416e-04, 4.46310714e-04, 4.95669604e-04, 4.96018649e-04,\n",
       "        4.89111479e-04, 3.46829884e-04, 4.59414842e-04, 4.90000969e-04,\n",
       "        4.94889181e-04, 4.54765440e-04, 4.52836139e-04, 4.93526341e-04,\n",
       "        4.92632325e-04, 4.97661791e-04, 4.94669889e-04, 5.01931429e-04,\n",
       "        4.92945335e-04, 3.33804521e-04, 4.65512395e-04, 5.02670145e-04,\n",
       "        4.89247371e-04, 4.95429724e-04, 7.23216070e-04, 3.48350686e-04,\n",
       "        4.59820924e-04, 5.03626660e-04, 4.95446746e-04, 3.45985316e-04]),\n",
       " 'mean_score_time': array([0.00186658, 0.00128133, 0.00200309, 0.00228333, 0.00128215,\n",
       "        0.00113971, 0.00071222, 0.00085582, 0.00085493, 0.00056924,\n",
       "        0.00085681, 0.00113957, 0.00128681, 0.00085143, 0.00099441,\n",
       "        0.00126549, 0.00113858, 0.00142946, 0.0012817 , 0.00114216,\n",
       "        0.00112428, 0.0015645 , 0.00113331, 0.00113341, 0.00143337,\n",
       "        0.00114298, 0.00113603, 0.0011377 , 0.00099652, 0.00157223,\n",
       "        0.00114063, 0.00127881, 0.00213586, 0.00185932, 0.0010125 ,\n",
       "        0.00113552, 0.00114318, 0.00128491, 0.0008578 , 0.00097517,\n",
       "        0.00084376, 0.00112956, 0.0005657 , 0.00085786, 0.000855  ,\n",
       "        0.00071624, 0.00113886, 0.00099295, 0.00099925, 0.00056475,\n",
       "        0.00085344, 0.00085647, 0.00114455, 0.00113021, 0.00085657,\n",
       "        0.00085422, 0.00055896, 0.00085398, 0.00142438, 0.00157091,\n",
       "        0.0014237 , 0.00156927, 0.00170977, 0.00099247, 0.00142261,\n",
       "        0.001277  , 0.0008533 , 0.00057718, 0.00085599, 0.00070878,\n",
       "        0.00098947, 0.00113985, 0.00085078, 0.00070633, 0.00085432,\n",
       "        0.0012954 , 0.00143051, 0.00157435, 0.00143259, 0.00155381,\n",
       "        0.00142063, 0.00172094, 0.00127792, 0.00128467, 0.00113981,\n",
       "        0.00099948, 0.00113967, 0.000855  , 0.00071236, 0.00114039,\n",
       "        0.00085698, 0.00085214, 0.0009986 , 0.00085241, 0.00056982,\n",
       "        0.0008547 , 0.00085487, 0.00099724, 0.00070763, 0.00071239,\n",
       "        0.00071219, 0.00085092, 0.00114025, 0.00099918, 0.00085487,\n",
       "        0.00114509, 0.00171259, 0.00128467, 0.00157114, 0.00157142,\n",
       "        0.0012817 , 0.00128712, 0.0015704 , 0.00142642, 0.00114271,\n",
       "        0.0005703 , 0.00099656, 0.00099131, 0.00128685, 0.00113974,\n",
       "        0.00085599, 0.00113378, 0.00098845, 0.00085122, 0.00086679,\n",
       "        0.00070909, 0.00114557, 0.00085337, 0.00099741, 0.00070361,\n",
       "        0.00099233, 0.00086369, 0.00085466, 0.00085371, 0.00086423,\n",
       "        0.00071199, 0.00085415, 0.00099679, 0.00085381, 0.00099843,\n",
       "        0.00071849, 0.00128341, 0.00099203, 0.00086617, 0.00100327,\n",
       "        0.00070126, 0.00071308, 0.00085378, 0.0009955 , 0.00099853,\n",
       "        0.00098041, 0.00085436, 0.00085143, 0.00099519, 0.00056989,\n",
       "        0.00099717, 0.00071062, 0.00100555, 0.00086134, 0.00085487,\n",
       "        0.00100483, 0.00085466, 0.00084891, 0.00056338, 0.00070572,\n",
       "        0.00085255, 0.00084805, 0.00099015, 0.00085364, 0.00085483,\n",
       "        0.00099942, 0.00100221, 0.00085851, 0.00085303, 0.0007126 ,\n",
       "        0.00085487, 0.0010047 , 0.00071618, 0.00072064, 0.0008707 ,\n",
       "        0.00113743, 0.00085715, 0.0008609 , 0.00099935, 0.00057013,\n",
       "        0.00086362, 0.00071352, 0.00085497, 0.00071073, 0.00084812,\n",
       "        0.00070899, 0.00114012, 0.00086025, 0.00099604, 0.00098205,\n",
       "        0.00099012, 0.0010003 , 0.00098705, 0.00099628, 0.00113913,\n",
       "        0.00100436, 0.00086611, 0.00099754, 0.00086147, 0.00071471,\n",
       "        0.00098637, 0.00100558, 0.00084441, 0.00085507, 0.00084707,\n",
       "        0.00071212, 0.00055913, 0.00071161, 0.00099836, 0.00100149,\n",
       "        0.00086457, 0.00100875, 0.0011408 , 0.00086069, 0.0014316 ,\n",
       "        0.0009878 , 0.00142976, 0.00114792, 0.00113109, 0.00099131,\n",
       "        0.00170708, 0.00099376, 0.00085385, 0.00113085, 0.00072421,\n",
       "        0.00071325, 0.00086669, 0.00113341, 0.0008581 , 0.00071904,\n",
       "        0.00084724, 0.00114424, 0.0009969 , 0.00099581, 0.00114141,\n",
       "        0.0009972 , 0.00085483, 0.00085637, 0.00099754, 0.00113998,\n",
       "        0.00085272, 0.00085493, 0.00071042, 0.00099744, 0.00085483,\n",
       "        0.00099809, 0.00084785, 0.00056434, 0.00099727, 0.00085432,\n",
       "        0.00070752, 0.00100235, 0.00085497, 0.00127826, 0.00085364,\n",
       "        0.00085034, 0.00071938, 0.00085531, 0.00099295, 0.00085834,\n",
       "        0.00099836, 0.00084775, 0.00085514, 0.00085613, 0.00100398,\n",
       "        0.00071253, 0.00099226, 0.00099444, 0.00099942, 0.00085385,\n",
       "        0.00114097, 0.00099604, 0.00099724, 0.00071226, 0.00114199,\n",
       "        0.00099938, 0.00085473, 0.00099741, 0.00085374, 0.00113995,\n",
       "        0.00099567, 0.00099615, 0.00071222, 0.00099669, 0.00071239,\n",
       "        0.00056985, 0.00113886, 0.00099727, 0.00099955, 0.00071229,\n",
       "        0.00099734, 0.0008548 , 0.0008533 , 0.00085483, 0.00085473,\n",
       "        0.00071168, 0.00085476, 0.0008579 , 0.00085793, 0.00085493,\n",
       "        0.00070984, 0.0004266 , 0.00099557, 0.00085344, 0.00056904,\n",
       "        0.00071239, 0.00071243, 0.00099741, 0.00114625, 0.00085476,\n",
       "        0.00071107, 0.00099625, 0.00086556, 0.00084928, 0.00085207,\n",
       "        0.00099509, 0.00028532, 0.00100497, 0.00071771, 0.00084932,\n",
       "        0.00099083, 0.0009907 , 0.00071829, 0.00113082, 0.0009954 ,\n",
       "        0.00085473, 0.00085429, 0.00099652, 0.00084833, 0.00085793,\n",
       "        0.00113899, 0.00085763, 0.00071825, 0.00114329, 0.00099962,\n",
       "        0.00071338, 0.00099744, 0.00099737, 0.00085204, 0.00070565,\n",
       "        0.00114891, 0.00100429, 0.00072534, 0.00100061, 0.0009957 ,\n",
       "        0.00085575, 0.00071233, 0.00084986, 0.00085746, 0.00099584,\n",
       "        0.00085643, 0.0008548 , 0.00113525, 0.00085245, 0.00084846,\n",
       "        0.00113644, 0.00071219, 0.00099673, 0.00085565, 0.00085262,\n",
       "        0.00099557, 0.00071199, 0.00084795, 0.0008563 , 0.00113   ,\n",
       "        0.00099751, 0.00057234, 0.00099724, 0.00056985, 0.00099812,\n",
       "        0.00085637, 0.0008548 , 0.00113967, 0.00099509, 0.00056982,\n",
       "        0.00071236, 0.00071236, 0.00071028, 0.00099727, 0.00056999,\n",
       "        0.00071253, 0.00056996, 0.00099959, 0.00056989, 0.00085545,\n",
       "        0.0008547 , 0.00128348, 0.00128395, 0.00085385, 0.00128143,\n",
       "        0.0012799 , 0.00113995, 0.00128041, 0.00114192, 0.00100221,\n",
       "        0.00085167, 0.00143116, 0.00128572, 0.00100436, 0.00099673,\n",
       "        0.00099277, 0.00114005, 0.00071209, 0.00099169, 0.00099669,\n",
       "        0.00099741, 0.00099455, 0.00100197, 0.00098933, 0.00056873,\n",
       "        0.00100214, 0.00071243, 0.00071945, 0.00085793, 0.0010032 ,\n",
       "        0.00100197, 0.00086519, 0.00071209, 0.00085487, 0.00071801,\n",
       "        0.00099557, 0.00099281, 0.00057578, 0.0005659 , 0.00086233,\n",
       "        0.00098865, 0.00085892, 0.00086239, 0.00099564, 0.00085456,\n",
       "        0.0009924 , 0.00071124, 0.00113508, 0.00071093, 0.00070664,\n",
       "        0.00071287, 0.00070742, 0.00085974, 0.000855  , 0.00084175,\n",
       "        0.00085003, 0.00071328, 0.00114107]),\n",
       " 'std_score_time': array([8.53374887e-04, 4.50875401e-04, 1.32265870e-03, 1.38690189e-03,\n",
       "        8.78677403e-04, 3.49109231e-04, 4.50450297e-04, 3.49394781e-04,\n",
       "        3.49058559e-04, 4.93006351e-04, 3.49819190e-04, 3.49166192e-04,\n",
       "        4.43942029e-04, 3.47769799e-04, 5.33146157e-04, 4.38072925e-04,\n",
       "        3.48797077e-04, 4.96082942e-04, 4.53018540e-04, 8.39761177e-04,\n",
       "        3.41768590e-04, 7.31074364e-04, 3.49599270e-04, 3.46013681e-04,\n",
       "        1.18161497e-03, 3.61414773e-04, 3.42221244e-04, 3.44132786e-04,\n",
       "        5.29147951e-04, 1.29664442e-03, 3.51167303e-04, 1.28029043e-03,\n",
       "        1.12140269e-03, 9.86736052e-04, 9.41201006e-04, 3.49536035e-04,\n",
       "        8.39683461e-04, 8.76511311e-04, 6.29859605e-04, 5.23494320e-04,\n",
       "        3.44921097e-04, 3.38391305e-04, 4.90028606e-04, 3.50367263e-04,\n",
       "        3.49057163e-04, 4.53068692e-04, 3.43057167e-04, 1.25854522e-05,\n",
       "        5.00180615e-06, 7.18728792e-04, 3.48415868e-04, 3.49666204e-04,\n",
       "        3.51940316e-04, 3.37579008e-04, 3.49860577e-04, 3.48738626e-04,\n",
       "        4.84372508e-04, 3.48647149e-04, 1.49363034e-03, 1.05516929e-03,\n",
       "        9.01182878e-04, 7.28587517e-04, 8.77880498e-04, 1.18517327e-05,\n",
       "        7.23036166e-04, 4.43010159e-04, 3.48367064e-04, 4.99988317e-04,\n",
       "        3.49932871e-04, 4.48345460e-04, 1.62896298e-05, 3.49741085e-04,\n",
       "        3.47546626e-04, 4.46858605e-04, 3.48783803e-04, 4.56987456e-04,\n",
       "        7.26399498e-04, 7.28525921e-04, 7.53743691e-04, 7.17325943e-04,\n",
       "        1.05611233e-03, 1.16855970e-03, 8.77271391e-04, 6.99725760e-04,\n",
       "        8.30824098e-04, 5.24587220e-06, 3.49123157e-04, 3.49053557e-04,\n",
       "        4.50536455e-04, 3.50388423e-04, 3.49895580e-04, 3.47939093e-04,\n",
       "        5.35315206e-04, 6.36639583e-04, 4.93478954e-04, 6.36911093e-04,\n",
       "        3.48997984e-04, 1.66858247e-07, 4.47601695e-04, 4.50557985e-04,\n",
       "        4.50429505e-04, 3.47429854e-04, 6.37848514e-04, 4.78440140e-06,\n",
       "        6.37322338e-04, 3.53890381e-04, 1.02831670e-03, 8.81114787e-04,\n",
       "        7.26347496e-04, 9.07850731e-04, 6.96827856e-04, 8.87460585e-04,\n",
       "        1.29388680e-03, 1.50033880e-03, 9.88964170e-04, 4.93892343e-04,\n",
       "        1.90064654e-06, 1.04984870e-05, 1.27464567e-03, 3.49637803e-04,\n",
       "        3.49466796e-04, 3.39990145e-04, 5.22437035e-04, 3.48213666e-04,\n",
       "        3.54239233e-04, 4.48573904e-04, 3.46464010e-04, 3.49043490e-04,\n",
       "        3.38822232e-06, 4.45336903e-04, 5.26354474e-04, 3.53043254e-04,\n",
       "        3.48918558e-04, 3.48540884e-04, 3.53196929e-04, 4.50301365e-04,\n",
       "        3.48711391e-04, 2.52134535e-06, 3.48577408e-04, 5.33021372e-04,\n",
       "        4.54557901e-04, 4.38035212e-04, 9.90548845e-06, 3.54020912e-04,\n",
       "        1.80574110e-05, 4.43791352e-04, 4.50995312e-04, 3.48555219e-04,\n",
       "        1.58075624e-06, 1.61416130e-06, 2.32952081e-05, 3.48807251e-04,\n",
       "        3.48075995e-04, 5.97125653e-06, 4.93540983e-04, 2.61751257e-06,\n",
       "        4.49461795e-04, 2.83716269e-05, 3.52055108e-04, 3.49026254e-04,\n",
       "        5.37417249e-04, 3.48916976e-04, 3.46756874e-04, 4.88103252e-04,\n",
       "        4.46594466e-04, 3.48060994e-04, 3.46594081e-04, 5.22949370e-04,\n",
       "        3.48500882e-04, 3.48992912e-04, 5.33668546e-04, 1.18518306e-05,\n",
       "        3.50561897e-04, 3.48279696e-04, 4.50692156e-04, 3.49694655e-04,\n",
       "        1.33927349e-05, 4.52984158e-04, 4.55997633e-04, 3.55824008e-04,\n",
       "        3.56249189e-04, 3.50027949e-04, 3.51785749e-04, 5.39695001e-04,\n",
       "        4.93748155e-04, 3.52900820e-04, 4.51613012e-04, 3.49057572e-04,\n",
       "        4.49510956e-04, 3.46526450e-04, 4.48598004e-04, 6.36281217e-04,\n",
       "        3.51365769e-04, 1.99522977e-05, 7.39911934e-04, 5.24275422e-04,\n",
       "        1.89045067e-05, 5.33337649e-04, 5.35798076e-04, 3.50625940e-04,\n",
       "        1.24159990e-05, 3.54019690e-04, 7.76443855e-06, 3.51805238e-04,\n",
       "        4.52284537e-04, 2.82875175e-05, 1.41823784e-05, 3.45208243e-04,\n",
       "        3.49595414e-04, 3.45982630e-04, 4.50389319e-04, 4.84425861e-04,\n",
       "        4.50072517e-04, 2.34246238e-06, 5.33921495e-04, 3.53400236e-04,\n",
       "        1.75316995e-05, 8.32373523e-04, 3.51665014e-04, 1.05699232e-03,\n",
       "        1.58228195e-05, 1.05852337e-03, 3.60485371e-04, 3.40502119e-04,\n",
       "        5.26418449e-04, 1.15489865e-03, 7.69555468e-06, 3.48585521e-04,\n",
       "        3.41574522e-04, 4.58218213e-04, 4.51099668e-04, 3.54207380e-04,\n",
       "        3.37495468e-04, 3.50463180e-04, 4.54935287e-04, 6.25249983e-04,\n",
       "        6.39070554e-04, 5.32572258e-04, 5.33289316e-04, 3.53183305e-04,\n",
       "        5.32954489e-04, 3.48984047e-04, 3.49630454e-04, 5.33591874e-04,\n",
       "        3.48997961e-04, 3.48139176e-04, 3.49025802e-04, 4.49331076e-04,\n",
       "        5.33145646e-04, 3.48984070e-04, 1.83945609e-05, 3.46389422e-04,\n",
       "        4.88822963e-04, 2.57236039e-06, 3.48779985e-04, 4.47715973e-04,\n",
       "        1.33492681e-05, 3.49063388e-04, 4.41548484e-04, 3.48515724e-04,\n",
       "        3.47506015e-04, 4.55193630e-04, 6.30190140e-04, 5.24599619e-04,\n",
       "        3.50584643e-04, 5.99761982e-06, 3.46434671e-04, 3.49114581e-04,\n",
       "        6.38618120e-04, 1.17556145e-05, 6.91740939e-04, 1.42797908e-05,\n",
       "        6.95103633e-06, 9.05760091e-06, 3.48585731e-04, 3.46380125e-04,\n",
       "        3.09475945e-06, 1.66858247e-07, 4.50471842e-04, 3.48125963e-04,\n",
       "        5.37043079e-04, 3.48942326e-04, 5.33145646e-04, 3.48667179e-04,\n",
       "        3.49109208e-04, 5.33161418e-04, 2.45277839e-06, 4.50450297e-04,\n",
       "        1.21474637e-06, 4.50558021e-04, 4.93508448e-04, 3.46536808e-04,\n",
       "        1.98601038e-07, 5.60425990e-06, 4.50493365e-04, 7.90011100e-07,\n",
       "        3.48970151e-04, 6.34524124e-04, 3.48984047e-04, 3.48942326e-04,\n",
       "        4.50108172e-04, 3.48956276e-04, 3.50313727e-04, 3.50325251e-04,\n",
       "        3.49025779e-04, 4.48980678e-04, 4.92596832e-04, 4.16226885e-06,\n",
       "        3.48432230e-04, 4.92804385e-04, 4.50558003e-04, 4.50579530e-04,\n",
       "        2.50287370e-07, 3.54815980e-04, 3.48956252e-04, 4.49726979e-04,\n",
       "        2.60507354e-06, 6.47970366e-04, 3.46953686e-04, 3.48004856e-04,\n",
       "        5.45338601e-04, 4.51129367e-04, 1.45791846e-05, 4.54081773e-04,\n",
       "        3.46881364e-04, 1.46768878e-05, 5.21769424e-04, 4.54530940e-04,\n",
       "        3.41437834e-04, 4.81750515e-06, 3.48953729e-04, 3.48762306e-04,\n",
       "        5.31749804e-04, 3.46540527e-04, 3.50289552e-04, 6.28481733e-04,\n",
       "        3.50358780e-04, 4.54392499e-04, 3.52507118e-04, 2.51443900e-05,\n",
       "        4.51186816e-04, 5.32958496e-04, 1.53306926e-06, 3.47849584e-04,\n",
       "        4.46491406e-04, 3.45110012e-04, 5.33972304e-04, 4.59141370e-04,\n",
       "        2.22507730e-05, 2.30549355e-05, 3.49374650e-04, 4.50518327e-04,\n",
       "        3.47156793e-04, 3.50178538e-04, 1.75399687e-06, 3.49641347e-04,\n",
       "        3.48982112e-04, 3.52815006e-04, 3.48026963e-04, 3.46684078e-04,\n",
       "        3.52093306e-04, 4.50431939e-04, 1.82847507e-06, 3.49326573e-04,\n",
       "        3.48690306e-04, 5.23653765e-04, 4.50301095e-04, 6.26985741e-04,\n",
       "        3.49596994e-04, 6.23569964e-04, 5.33209393e-04, 4.95690154e-04,\n",
       "        2.09958690e-07, 4.93508465e-04, 5.33275355e-04, 3.49630477e-04,\n",
       "        3.48970128e-04, 3.49123087e-04, 5.42439026e-06, 4.93478954e-04,\n",
       "        4.50536437e-04, 4.50536455e-04, 4.49251653e-04, 2.68187110e-07,\n",
       "        4.93626451e-04, 4.50644161e-04, 4.93596940e-04, 5.37299044e-04,\n",
       "        4.93538054e-04, 6.37399983e-04, 3.48928419e-04, 8.81623805e-04,\n",
       "        8.80606665e-04, 6.35496185e-04, 6.96617680e-04, 8.77033455e-04,\n",
       "        8.31618687e-04, 6.99125222e-04, 9.90242875e-04, 5.44069539e-04,\n",
       "        3.47795646e-04, 1.18898848e-03, 7.18829172e-04, 1.53430974e-05,\n",
       "        2.25413079e-06, 5.23283958e-04, 3.31374888e-04, 4.50365091e-04,\n",
       "        5.22643822e-04, 1.18084879e-06, 2.65447995e-06, 6.22875377e-06,\n",
       "        1.48613163e-05, 1.27037107e-05, 4.92545217e-04, 1.27017016e-05,\n",
       "        4.50583117e-04, 4.55233592e-04, 3.50525120e-04, 1.14701139e-05,\n",
       "        1.57793566e-05, 3.53623828e-04, 4.50365740e-04, 3.49000846e-04,\n",
       "        4.54354342e-04, 2.83740801e-06, 5.23470322e-04, 4.98863956e-04,\n",
       "        4.90162951e-04, 3.52347571e-04, 1.40950782e-05, 3.50716679e-04,\n",
       "        6.40703273e-04, 2.75695070e-06, 3.48877385e-04, 1.48842482e-05,\n",
       "        4.49841705e-04, 3.36773153e-04, 4.49633681e-04, 4.47158032e-04,\n",
       "        4.50864419e-04, 4.47741757e-04, 3.51335644e-04, 3.49064445e-04,\n",
       "        3.44063556e-04, 6.28617155e-04, 4.51507594e-04, 3.48580589e-04]),\n",
       " 'param_max_depth': masked_array(data=[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 2, 2, 2, 2,\n",
       "                    2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3,\n",
       "                    4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5,\n",
       "                    6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7,\n",
       "                    8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                    2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3,\n",
       "                    4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5,\n",
       "                    6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7,\n",
       "                    8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                    2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3,\n",
       "                    4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5,\n",
       "                    6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7,\n",
       "                    8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                    2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3,\n",
       "                    4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5,\n",
       "                    6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7,\n",
       "                    8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                    2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3,\n",
       "                    4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5,\n",
       "                    6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7,\n",
       "                    8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                    2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3,\n",
       "                    4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5,\n",
       "                    6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7,\n",
       "                    8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                    2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 2},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 3},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 4},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 5},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 6},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 7},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 8},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 9},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 3, 'min_samples_split': 2},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 3, 'min_samples_split': 3},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 3, 'min_samples_split': 4},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 3, 'min_samples_split': 5},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 3, 'min_samples_split': 6},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 3, 'min_samples_split': 7},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 3, 'min_samples_split': 8},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 3, 'min_samples_split': 9},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 2},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 3},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 4},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 5},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 6},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 7},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 8},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 9},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 2},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 3},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 4},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 5},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 6},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 7},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 8},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 9},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 6, 'min_samples_split': 2},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 6, 'min_samples_split': 3},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 6, 'min_samples_split': 4},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 6, 'min_samples_split': 5},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 6, 'min_samples_split': 6},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 6, 'min_samples_split': 7},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 6, 'min_samples_split': 8},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 6, 'min_samples_split': 9},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 7, 'min_samples_split': 2},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 7, 'min_samples_split': 3},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 7, 'min_samples_split': 4},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 7, 'min_samples_split': 5},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 7, 'min_samples_split': 6},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 7, 'min_samples_split': 7},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 7, 'min_samples_split': 8},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 7, 'min_samples_split': 9},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 8, 'min_samples_split': 2},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 8, 'min_samples_split': 3},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 8, 'min_samples_split': 4},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 8, 'min_samples_split': 5},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 8, 'min_samples_split': 6},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 8, 'min_samples_split': 7},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 8, 'min_samples_split': 8},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 8, 'min_samples_split': 9},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 9, 'min_samples_split': 2},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 9, 'min_samples_split': 3},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 9, 'min_samples_split': 4},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 9, 'min_samples_split': 5},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 9, 'min_samples_split': 6},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 9, 'min_samples_split': 7},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 9, 'min_samples_split': 8},\n",
       "  {'max_depth': 3, 'min_samples_leaf': 9, 'min_samples_split': 9},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 2},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 3},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 4},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 5},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 6},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 7},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 8},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 9},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 2},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 3},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 4},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 5},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 6},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 7},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 8},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 9},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 4, 'min_samples_split': 2},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 4, 'min_samples_split': 3},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 4, 'min_samples_split': 4},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 4, 'min_samples_split': 5},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 4, 'min_samples_split': 6},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 4, 'min_samples_split': 7},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 4, 'min_samples_split': 8},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 4, 'min_samples_split': 9},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 5, 'min_samples_split': 2},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 5, 'min_samples_split': 3},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 5, 'min_samples_split': 4},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 5, 'min_samples_split': 5},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 5, 'min_samples_split': 6},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 5, 'min_samples_split': 7},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 5, 'min_samples_split': 8},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 5, 'min_samples_split': 9},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 6, 'min_samples_split': 2},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 6, 'min_samples_split': 3},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 6, 'min_samples_split': 4},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 6, 'min_samples_split': 5},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 6, 'min_samples_split': 6},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 6, 'min_samples_split': 7},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 6, 'min_samples_split': 8},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 6, 'min_samples_split': 9},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 7, 'min_samples_split': 2},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 7, 'min_samples_split': 3},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 7, 'min_samples_split': 4},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 7, 'min_samples_split': 5},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 7, 'min_samples_split': 6},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 7, 'min_samples_split': 7},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 7, 'min_samples_split': 8},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 7, 'min_samples_split': 9},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 8, 'min_samples_split': 2},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 8, 'min_samples_split': 3},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 8, 'min_samples_split': 4},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 8, 'min_samples_split': 5},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 8, 'min_samples_split': 6},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 8, 'min_samples_split': 7},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 8, 'min_samples_split': 8},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 8, 'min_samples_split': 9},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 9, 'min_samples_split': 2},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 9, 'min_samples_split': 3},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 9, 'min_samples_split': 4},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 9, 'min_samples_split': 5},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 9, 'min_samples_split': 6},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 9, 'min_samples_split': 7},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 9, 'min_samples_split': 8},\n",
       "  {'max_depth': 4, 'min_samples_leaf': 9, 'min_samples_split': 9},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 3},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 4},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 6},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 7},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 8},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 9},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 2},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 3},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 4},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 5},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 6},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 7},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 8},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 9},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 2},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 3},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 4},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 5},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 6},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 7},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 8},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 9},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 2},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 3},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 4},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 5},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 6},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 7},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 8},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 9},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 6, 'min_samples_split': 2},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 6, 'min_samples_split': 3},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 6, 'min_samples_split': 4},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 6, 'min_samples_split': 5},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 6, 'min_samples_split': 6},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 6, 'min_samples_split': 7},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 6, 'min_samples_split': 8},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 6, 'min_samples_split': 9},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 7, 'min_samples_split': 2},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 7, 'min_samples_split': 3},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 7, 'min_samples_split': 4},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 7, 'min_samples_split': 5},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 7, 'min_samples_split': 6},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 7, 'min_samples_split': 7},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 7, 'min_samples_split': 8},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 7, 'min_samples_split': 9},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 8, 'min_samples_split': 2},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 8, 'min_samples_split': 3},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 8, 'min_samples_split': 4},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 8, 'min_samples_split': 5},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 8, 'min_samples_split': 6},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 8, 'min_samples_split': 7},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 8, 'min_samples_split': 8},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 8, 'min_samples_split': 9},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 9, 'min_samples_split': 2},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 9, 'min_samples_split': 3},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 9, 'min_samples_split': 4},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 9, 'min_samples_split': 5},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 9, 'min_samples_split': 6},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 9, 'min_samples_split': 7},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 9, 'min_samples_split': 8},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 9, 'min_samples_split': 9},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 2},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 3},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 4},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 5},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 6},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 7},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 8},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 9},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 3, 'min_samples_split': 2},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 3, 'min_samples_split': 3},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 3, 'min_samples_split': 4},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 3, 'min_samples_split': 5},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 3, 'min_samples_split': 6},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 3, 'min_samples_split': 7},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 3, 'min_samples_split': 8},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 3, 'min_samples_split': 9},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 4, 'min_samples_split': 2},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 4, 'min_samples_split': 3},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 4, 'min_samples_split': 4},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 4, 'min_samples_split': 5},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 4, 'min_samples_split': 6},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 4, 'min_samples_split': 7},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 4, 'min_samples_split': 8},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 4, 'min_samples_split': 9},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 5, 'min_samples_split': 2},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 5, 'min_samples_split': 3},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 5, 'min_samples_split': 4},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 5, 'min_samples_split': 5},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 5, 'min_samples_split': 6},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 5, 'min_samples_split': 7},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 5, 'min_samples_split': 8},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 5, 'min_samples_split': 9},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 6, 'min_samples_split': 2},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 6, 'min_samples_split': 3},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 6, 'min_samples_split': 4},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 6, 'min_samples_split': 5},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 6, 'min_samples_split': 6},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 6, 'min_samples_split': 7},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 6, 'min_samples_split': 8},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 6, 'min_samples_split': 9},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 7, 'min_samples_split': 2},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 7, 'min_samples_split': 3},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 7, 'min_samples_split': 4},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 7, 'min_samples_split': 5},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 7, 'min_samples_split': 6},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 7, 'min_samples_split': 7},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 7, 'min_samples_split': 8},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 7, 'min_samples_split': 9},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 8, 'min_samples_split': 2},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 8, 'min_samples_split': 3},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 8, 'min_samples_split': 4},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 8, 'min_samples_split': 5},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 8, 'min_samples_split': 6},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 8, 'min_samples_split': 7},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 8, 'min_samples_split': 8},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 8, 'min_samples_split': 9},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 9, 'min_samples_split': 2},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 9, 'min_samples_split': 3},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 9, 'min_samples_split': 4},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 9, 'min_samples_split': 5},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 9, 'min_samples_split': 6},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 9, 'min_samples_split': 7},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 9, 'min_samples_split': 8},\n",
       "  {'max_depth': 6, 'min_samples_leaf': 9, 'min_samples_split': 9},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 2},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 3},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 4},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 5},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 6},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 7},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 8},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 9},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 3, 'min_samples_split': 2},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 3, 'min_samples_split': 3},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 3, 'min_samples_split': 4},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 3, 'min_samples_split': 5},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 3, 'min_samples_split': 6},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 3, 'min_samples_split': 7},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 3, 'min_samples_split': 8},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 3, 'min_samples_split': 9},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 2},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 3},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 4},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 5},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 6},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 7},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 8},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 9},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 5, 'min_samples_split': 2},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 5, 'min_samples_split': 3},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 5, 'min_samples_split': 4},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 5, 'min_samples_split': 5},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 5, 'min_samples_split': 6},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 5, 'min_samples_split': 7},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 5, 'min_samples_split': 8},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 5, 'min_samples_split': 9},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 6, 'min_samples_split': 2},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 6, 'min_samples_split': 3},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 6, 'min_samples_split': 4},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 6, 'min_samples_split': 5},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 6, 'min_samples_split': 6},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 6, 'min_samples_split': 7},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 6, 'min_samples_split': 8},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 6, 'min_samples_split': 9},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 7, 'min_samples_split': 2},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 7, 'min_samples_split': 3},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 7, 'min_samples_split': 4},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 7, 'min_samples_split': 5},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 7, 'min_samples_split': 6},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 7, 'min_samples_split': 7},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 7, 'min_samples_split': 8},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 7, 'min_samples_split': 9},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 8, 'min_samples_split': 2},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 8, 'min_samples_split': 3},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 8, 'min_samples_split': 4},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 8, 'min_samples_split': 5},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 8, 'min_samples_split': 6},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 8, 'min_samples_split': 7},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 8, 'min_samples_split': 8},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 8, 'min_samples_split': 9},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 9, 'min_samples_split': 2},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 9, 'min_samples_split': 3},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 9, 'min_samples_split': 4},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 9, 'min_samples_split': 5},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 9, 'min_samples_split': 6},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 9, 'min_samples_split': 7},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 9, 'min_samples_split': 8},\n",
       "  {'max_depth': 7, 'min_samples_leaf': 9, 'min_samples_split': 9},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 2, 'min_samples_split': 2},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 2, 'min_samples_split': 3},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 2, 'min_samples_split': 4},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 2, 'min_samples_split': 5},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 2, 'min_samples_split': 6},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 2, 'min_samples_split': 7},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 2, 'min_samples_split': 8},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 2, 'min_samples_split': 9},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 3, 'min_samples_split': 2},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 3, 'min_samples_split': 3},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 3, 'min_samples_split': 4},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 3, 'min_samples_split': 5},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 3, 'min_samples_split': 6},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 3, 'min_samples_split': 7},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 3, 'min_samples_split': 8},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 3, 'min_samples_split': 9},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 4, 'min_samples_split': 2},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 4, 'min_samples_split': 3},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 4, 'min_samples_split': 4},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 4, 'min_samples_split': 5},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 4, 'min_samples_split': 6},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 4, 'min_samples_split': 7},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 4, 'min_samples_split': 8},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 4, 'min_samples_split': 9},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 5, 'min_samples_split': 2},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 5, 'min_samples_split': 3},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 5, 'min_samples_split': 4},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 5, 'min_samples_split': 5},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 5, 'min_samples_split': 6},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 5, 'min_samples_split': 7},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 5, 'min_samples_split': 8},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 5, 'min_samples_split': 9},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 6, 'min_samples_split': 2},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 6, 'min_samples_split': 3},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 6, 'min_samples_split': 4},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 6, 'min_samples_split': 5},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 6, 'min_samples_split': 6},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 6, 'min_samples_split': 7},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 6, 'min_samples_split': 8},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 6, 'min_samples_split': 9},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 7, 'min_samples_split': 2},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 7, 'min_samples_split': 3},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 7, 'min_samples_split': 4},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 7, 'min_samples_split': 5},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 7, 'min_samples_split': 6},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 7, 'min_samples_split': 7},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 7, 'min_samples_split': 8},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 7, 'min_samples_split': 9},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 8, 'min_samples_split': 2},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 8, 'min_samples_split': 3},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 8, 'min_samples_split': 4},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 8, 'min_samples_split': 5},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 8, 'min_samples_split': 6},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 8, 'min_samples_split': 7},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 8, 'min_samples_split': 8},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 8, 'min_samples_split': 9},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 9, 'min_samples_split': 2},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 9, 'min_samples_split': 3},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 9, 'min_samples_split': 4},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 9, 'min_samples_split': 5},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 9, 'min_samples_split': 6},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 9, 'min_samples_split': 7},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 9, 'min_samples_split': 8},\n",
       "  {'max_depth': 8, 'min_samples_leaf': 9, 'min_samples_split': 9},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 2},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 3},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 4},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 5},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 6},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 7},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 8},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 9},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 3, 'min_samples_split': 2},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 3, 'min_samples_split': 3},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 3, 'min_samples_split': 4},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 3, 'min_samples_split': 5},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 3, 'min_samples_split': 6},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 3, 'min_samples_split': 7},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 3, 'min_samples_split': 8},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 3, 'min_samples_split': 9},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 4, 'min_samples_split': 2},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 4, 'min_samples_split': 3},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 4, 'min_samples_split': 4},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 4, 'min_samples_split': 5},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 4, 'min_samples_split': 6},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 4, 'min_samples_split': 7},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 4, 'min_samples_split': 8},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 4, 'min_samples_split': 9},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 5, 'min_samples_split': 2},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 5, 'min_samples_split': 3},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 5, 'min_samples_split': 4},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 5, 'min_samples_split': 5},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 5, 'min_samples_split': 6},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 5, 'min_samples_split': 7},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 5, 'min_samples_split': 8},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 5, 'min_samples_split': 9},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 6, 'min_samples_split': 2},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 6, 'min_samples_split': 3},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 6, 'min_samples_split': 4},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 6, 'min_samples_split': 5},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 6, 'min_samples_split': 6},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 6, 'min_samples_split': 7},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 6, 'min_samples_split': 8},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 6, 'min_samples_split': 9},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 7, 'min_samples_split': 2},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 7, 'min_samples_split': 3},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 7, 'min_samples_split': 4},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 7, 'min_samples_split': 5},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 7, 'min_samples_split': 6},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 7, 'min_samples_split': 7},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 7, 'min_samples_split': 8},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 7, 'min_samples_split': 9},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 8, 'min_samples_split': 2},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 8, 'min_samples_split': 3},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 8, 'min_samples_split': 4},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 8, 'min_samples_split': 5},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 8, 'min_samples_split': 6},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 8, 'min_samples_split': 7},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 8, 'min_samples_split': 8},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 8, 'min_samples_split': 9},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 9, 'min_samples_split': 2},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 9, 'min_samples_split': 3},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 9, 'min_samples_split': 4},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 9, 'min_samples_split': 5},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 9, 'min_samples_split': 6},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 9, 'min_samples_split': 7},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 9, 'min_samples_split': 8},\n",
       "  {'max_depth': 9, 'min_samples_leaf': 9, 'min_samples_split': 9}],\n",
       " 'split0_test_score': array([0.77669903, 0.77669903, 0.77669903, 0.77669903, 0.77669903,\n",
       "        0.77669903, 0.77669903, 0.77669903, 0.78640777, 0.78640777,\n",
       "        0.78640777, 0.78640777, 0.78640777, 0.78640777, 0.78640777,\n",
       "        0.78640777, 0.78640777, 0.78640777, 0.78640777, 0.78640777,\n",
       "        0.78640777, 0.78640777, 0.78640777, 0.78640777, 0.78640777,\n",
       "        0.78640777, 0.78640777, 0.78640777, 0.78640777, 0.78640777,\n",
       "        0.78640777, 0.78640777, 0.78640777, 0.78640777, 0.78640777,\n",
       "        0.78640777, 0.78640777, 0.78640777, 0.78640777, 0.78640777,\n",
       "        0.80582524, 0.80582524, 0.80582524, 0.80582524, 0.80582524,\n",
       "        0.80582524, 0.80582524, 0.80582524, 0.78640777, 0.78640777,\n",
       "        0.78640777, 0.78640777, 0.78640777, 0.78640777, 0.78640777,\n",
       "        0.78640777, 0.78640777, 0.78640777, 0.78640777, 0.78640777,\n",
       "        0.78640777, 0.78640777, 0.78640777, 0.78640777, 0.75728155,\n",
       "        0.75728155, 0.75728155, 0.75728155, 0.75728155, 0.75728155,\n",
       "        0.75728155, 0.75728155, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.78640777,\n",
       "        0.78640777, 0.78640777, 0.78640777, 0.78640777, 0.78640777,\n",
       "        0.78640777, 0.78640777, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.66019417, 0.66019417,\n",
       "        0.66019417, 0.66019417, 0.66019417, 0.66019417, 0.66019417,\n",
       "        0.66019417, 0.66990291, 0.66990291, 0.66990291, 0.66990291,\n",
       "        0.66990291, 0.66990291, 0.66990291, 0.66990291, 0.66990291,\n",
       "        0.66990291, 0.66990291, 0.66990291, 0.66990291, 0.66990291,\n",
       "        0.66990291, 0.66990291, 0.66990291, 0.66990291, 0.66990291,\n",
       "        0.66990291, 0.66990291, 0.66990291, 0.66990291, 0.66990291,\n",
       "        0.72815534, 0.72815534, 0.72815534, 0.72815534, 0.72815534,\n",
       "        0.72815534, 0.72815534, 0.72815534, 0.74757282, 0.74757282,\n",
       "        0.74757282, 0.74757282, 0.74757282, 0.74757282, 0.74757282,\n",
       "        0.74757282, 0.74757282, 0.74757282, 0.74757282, 0.74757282,\n",
       "        0.74757282, 0.74757282, 0.74757282, 0.74757282, 0.74757282,\n",
       "        0.74757282, 0.74757282, 0.74757282, 0.74757282, 0.74757282,\n",
       "        0.74757282, 0.74757282, 0.72815534, 0.72815534, 0.72815534,\n",
       "        0.72815534, 0.72815534, 0.72815534, 0.72815534, 0.72815534,\n",
       "        0.7184466 , 0.72815534, 0.7184466 , 0.7184466 , 0.7184466 ,\n",
       "        0.72815534, 0.72815534, 0.72815534, 0.7184466 , 0.7184466 ,\n",
       "        0.7184466 , 0.7184466 , 0.72815534, 0.72815534, 0.7184466 ,\n",
       "        0.72815534, 0.73786408, 0.73786408, 0.73786408, 0.73786408,\n",
       "        0.73786408, 0.73786408, 0.73786408, 0.73786408, 0.67961165,\n",
       "        0.67961165, 0.67961165, 0.67961165, 0.67961165, 0.67961165,\n",
       "        0.67961165, 0.67961165, 0.69902913, 0.69902913, 0.69902913,\n",
       "        0.69902913, 0.69902913, 0.69902913, 0.69902913, 0.69902913,\n",
       "        0.69902913, 0.69902913, 0.69902913, 0.69902913, 0.69902913,\n",
       "        0.69902913, 0.69902913, 0.69902913, 0.70873786, 0.70873786,\n",
       "        0.70873786, 0.70873786, 0.70873786, 0.70873786, 0.70873786,\n",
       "        0.70873786, 0.75728155, 0.75728155, 0.73786408, 0.75728155,\n",
       "        0.75728155, 0.75728155, 0.74757282, 0.74757282, 0.75728155,\n",
       "        0.75728155, 0.75728155, 0.76699029, 0.76699029, 0.75728155,\n",
       "        0.76699029, 0.76699029, 0.70873786, 0.70873786, 0.70873786,\n",
       "        0.7184466 , 0.70873786, 0.70873786, 0.70873786, 0.70873786,\n",
       "        0.72815534, 0.72815534, 0.72815534, 0.72815534, 0.72815534,\n",
       "        0.72815534, 0.72815534, 0.72815534, 0.7184466 , 0.7184466 ,\n",
       "        0.7184466 , 0.7184466 , 0.7184466 , 0.7184466 , 0.7184466 ,\n",
       "        0.7184466 , 0.73786408, 0.73786408, 0.73786408, 0.73786408,\n",
       "        0.73786408, 0.73786408, 0.73786408, 0.73786408, 0.75728155,\n",
       "        0.75728155, 0.75728155, 0.75728155, 0.75728155, 0.75728155,\n",
       "        0.75728155, 0.75728155, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.70873786, 0.69902913, 0.70873786, 0.70873786, 0.72815534,\n",
       "        0.70873786, 0.72815534, 0.72815534, 0.72815534, 0.73786408,\n",
       "        0.72815534, 0.7184466 , 0.72815534, 0.7184466 , 0.72815534,\n",
       "        0.72815534, 0.67961165, 0.67961165, 0.66990291, 0.66990291,\n",
       "        0.66990291, 0.67961165, 0.67961165, 0.67961165, 0.68932039,\n",
       "        0.68932039, 0.68932039, 0.68932039, 0.68932039, 0.68932039,\n",
       "        0.68932039, 0.68932039, 0.69902913, 0.69902913, 0.69902913,\n",
       "        0.69902913, 0.69902913, 0.69902913, 0.69902913, 0.69902913,\n",
       "        0.7184466 , 0.7184466 , 0.7184466 , 0.7184466 , 0.7184466 ,\n",
       "        0.7184466 , 0.7184466 , 0.7184466 , 0.75728155, 0.75728155,\n",
       "        0.75728155, 0.75728155, 0.75728155, 0.75728155, 0.75728155,\n",
       "        0.75728155, 0.76699029, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.72815534,\n",
       "        0.74757282, 0.73786408, 0.74757282, 0.73786408, 0.75728155,\n",
       "        0.74757282, 0.73786408, 0.74757282, 0.73786408, 0.74757282,\n",
       "        0.75728155, 0.75728155, 0.74757282, 0.75728155, 0.74757282,\n",
       "        0.70873786, 0.70873786, 0.70873786, 0.69902913, 0.69902913,\n",
       "        0.70873786, 0.70873786, 0.70873786, 0.70873786, 0.70873786,\n",
       "        0.70873786, 0.70873786, 0.70873786, 0.70873786, 0.70873786,\n",
       "        0.70873786, 0.68932039, 0.68932039, 0.68932039, 0.68932039,\n",
       "        0.68932039, 0.68932039, 0.68932039, 0.68932039, 0.7184466 ,\n",
       "        0.7184466 , 0.7184466 , 0.7184466 , 0.7184466 , 0.7184466 ,\n",
       "        0.7184466 , 0.7184466 , 0.75728155, 0.75728155, 0.75728155,\n",
       "        0.75728155, 0.75728155, 0.75728155, 0.75728155, 0.75728155,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029]),\n",
       " 'split1_test_score': array([0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.73786408,\n",
       "        0.73786408, 0.73786408, 0.73786408, 0.73786408, 0.73786408,\n",
       "        0.73786408, 0.73786408, 0.73786408, 0.73786408, 0.73786408,\n",
       "        0.73786408, 0.73786408, 0.73786408, 0.73786408, 0.73786408,\n",
       "        0.73786408, 0.73786408, 0.73786408, 0.73786408, 0.73786408,\n",
       "        0.73786408, 0.73786408, 0.73786408, 0.75728155, 0.75728155,\n",
       "        0.75728155, 0.75728155, 0.75728155, 0.75728155, 0.75728155,\n",
       "        0.75728155, 0.75728155, 0.75728155, 0.75728155, 0.75728155,\n",
       "        0.75728155, 0.75728155, 0.75728155, 0.75728155, 0.73786408,\n",
       "        0.73786408, 0.73786408, 0.73786408, 0.73786408, 0.73786408,\n",
       "        0.73786408, 0.73786408, 0.73786408, 0.73786408, 0.73786408,\n",
       "        0.73786408, 0.73786408, 0.73786408, 0.73786408, 0.73786408,\n",
       "        0.75728155, 0.75728155, 0.75728155, 0.75728155, 0.75728155,\n",
       "        0.75728155, 0.75728155, 0.75728155, 0.7184466 , 0.7184466 ,\n",
       "        0.7184466 , 0.7184466 , 0.7184466 , 0.7184466 , 0.72815534,\n",
       "        0.72815534, 0.7184466 , 0.7184466 , 0.7184466 , 0.7184466 ,\n",
       "        0.7184466 , 0.7184466 , 0.72815534, 0.72815534, 0.72815534,\n",
       "        0.72815534, 0.72815534, 0.72815534, 0.72815534, 0.72815534,\n",
       "        0.72815534, 0.72815534, 0.72815534, 0.72815534, 0.72815534,\n",
       "        0.72815534, 0.72815534, 0.72815534, 0.72815534, 0.72815534,\n",
       "        0.72815534, 0.72815534, 0.72815534, 0.72815534, 0.72815534,\n",
       "        0.72815534, 0.72815534, 0.72815534, 0.7184466 , 0.7184466 ,\n",
       "        0.7184466 , 0.7184466 , 0.7184466 , 0.7184466 , 0.7184466 ,\n",
       "        0.7184466 , 0.7184466 , 0.7184466 , 0.7184466 , 0.7184466 ,\n",
       "        0.7184466 , 0.7184466 , 0.7184466 , 0.7184466 , 0.75728155,\n",
       "        0.75728155, 0.75728155, 0.75728155, 0.75728155, 0.75728155,\n",
       "        0.75728155, 0.75728155, 0.73786408, 0.73786408, 0.73786408,\n",
       "        0.73786408, 0.73786408, 0.73786408, 0.74757282, 0.74757282,\n",
       "        0.74757282, 0.74757282, 0.74757282, 0.74757282, 0.74757282,\n",
       "        0.74757282, 0.75728155, 0.75728155, 0.75728155, 0.75728155,\n",
       "        0.75728155, 0.75728155, 0.75728155, 0.75728155, 0.75728155,\n",
       "        0.75728155, 0.74757282, 0.74757282, 0.74757282, 0.74757282,\n",
       "        0.74757282, 0.74757282, 0.74757282, 0.74757282, 0.74757282,\n",
       "        0.73786408, 0.74757282, 0.73786408, 0.73786408, 0.74757282,\n",
       "        0.73786408, 0.73786408, 0.70873786, 0.70873786, 0.70873786,\n",
       "        0.70873786, 0.70873786, 0.70873786, 0.70873786, 0.70873786,\n",
       "        0.7184466 , 0.7184466 , 0.7184466 , 0.7184466 , 0.7184466 ,\n",
       "        0.7184466 , 0.7184466 , 0.7184466 , 0.74757282, 0.74757282,\n",
       "        0.74757282, 0.74757282, 0.74757282, 0.74757282, 0.74757282,\n",
       "        0.74757282, 0.73786408, 0.74757282, 0.72815534, 0.73786408,\n",
       "        0.74757282, 0.74757282, 0.75728155, 0.74757282, 0.74757282,\n",
       "        0.74757282, 0.74757282, 0.74757282, 0.74757282, 0.74757282,\n",
       "        0.75728155, 0.75728155, 0.75728155, 0.75728155, 0.75728155,\n",
       "        0.75728155, 0.75728155, 0.75728155, 0.75728155, 0.75728155,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.75728155, 0.75728155,\n",
       "        0.75728155, 0.75728155, 0.75728155, 0.76699029, 0.75728155,\n",
       "        0.76699029, 0.70873786, 0.70873786, 0.70873786, 0.70873786,\n",
       "        0.70873786, 0.70873786, 0.70873786, 0.70873786, 0.7184466 ,\n",
       "        0.7184466 , 0.7184466 , 0.7184466 , 0.7184466 , 0.7184466 ,\n",
       "        0.7184466 , 0.7184466 , 0.75728155, 0.75728155, 0.75728155,\n",
       "        0.75728155, 0.75728155, 0.75728155, 0.75728155, 0.75728155,\n",
       "        0.72815534, 0.7184466 , 0.72815534, 0.72815534, 0.73786408,\n",
       "        0.73786408, 0.74757282, 0.75728155, 0.75728155, 0.75728155,\n",
       "        0.75728155, 0.75728155, 0.75728155, 0.75728155, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.77669903,\n",
       "        0.77669903, 0.77669903, 0.77669903, 0.77669903, 0.76699029,\n",
       "        0.77669903, 0.77669903, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.75728155, 0.76699029, 0.75728155, 0.76699029, 0.76699029,\n",
       "        0.7184466 , 0.7184466 , 0.7184466 , 0.7184466 , 0.7184466 ,\n",
       "        0.7184466 , 0.7184466 , 0.7184466 , 0.72815534, 0.72815534,\n",
       "        0.72815534, 0.72815534, 0.72815534, 0.72815534, 0.72815534,\n",
       "        0.72815534, 0.75728155, 0.75728155, 0.75728155, 0.75728155,\n",
       "        0.75728155, 0.75728155, 0.75728155, 0.75728155, 0.72815534,\n",
       "        0.72815534, 0.7184466 , 0.7184466 , 0.73786408, 0.73786408,\n",
       "        0.74757282, 0.75728155, 0.75728155, 0.75728155, 0.75728155,\n",
       "        0.75728155, 0.75728155, 0.75728155, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.77669903, 0.77669903,\n",
       "        0.77669903, 0.76699029, 0.77669903, 0.77669903, 0.77669903,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.77669903, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.7184466 ,\n",
       "        0.7184466 , 0.7184466 , 0.7184466 , 0.7184466 , 0.7184466 ,\n",
       "        0.7184466 , 0.7184466 , 0.72815534, 0.72815534, 0.72815534,\n",
       "        0.72815534, 0.72815534, 0.72815534, 0.72815534, 0.72815534,\n",
       "        0.75728155, 0.75728155, 0.75728155, 0.75728155, 0.75728155,\n",
       "        0.75728155, 0.75728155, 0.75728155]),\n",
       " 'split2_test_score': array([0.84466019, 0.84466019, 0.84466019, 0.84466019, 0.84466019,\n",
       "        0.84466019, 0.84466019, 0.84466019, 0.84466019, 0.84466019,\n",
       "        0.84466019, 0.84466019, 0.84466019, 0.84466019, 0.84466019,\n",
       "        0.84466019, 0.84466019, 0.84466019, 0.84466019, 0.84466019,\n",
       "        0.84466019, 0.84466019, 0.84466019, 0.84466019, 0.84466019,\n",
       "        0.84466019, 0.84466019, 0.84466019, 0.84466019, 0.84466019,\n",
       "        0.84466019, 0.84466019, 0.84466019, 0.84466019, 0.84466019,\n",
       "        0.84466019, 0.84466019, 0.84466019, 0.84466019, 0.84466019,\n",
       "        0.84466019, 0.84466019, 0.84466019, 0.84466019, 0.84466019,\n",
       "        0.84466019, 0.84466019, 0.84466019, 0.84466019, 0.84466019,\n",
       "        0.84466019, 0.84466019, 0.84466019, 0.84466019, 0.84466019,\n",
       "        0.84466019, 0.84466019, 0.84466019, 0.84466019, 0.84466019,\n",
       "        0.84466019, 0.84466019, 0.84466019, 0.84466019, 0.82524272,\n",
       "        0.82524272, 0.82524272, 0.82524272, 0.82524272, 0.82524272,\n",
       "        0.82524272, 0.82524272, 0.82524272, 0.82524272, 0.82524272,\n",
       "        0.82524272, 0.82524272, 0.82524272, 0.82524272, 0.82524272,\n",
       "        0.82524272, 0.82524272, 0.82524272, 0.82524272, 0.82524272,\n",
       "        0.82524272, 0.82524272, 0.82524272, 0.83495146, 0.83495146,\n",
       "        0.83495146, 0.83495146, 0.83495146, 0.83495146, 0.83495146,\n",
       "        0.83495146, 0.83495146, 0.83495146, 0.83495146, 0.83495146,\n",
       "        0.83495146, 0.83495146, 0.83495146, 0.83495146, 0.83495146,\n",
       "        0.83495146, 0.83495146, 0.83495146, 0.83495146, 0.83495146,\n",
       "        0.83495146, 0.83495146, 0.83495146, 0.83495146, 0.83495146,\n",
       "        0.83495146, 0.83495146, 0.83495146, 0.83495146, 0.83495146,\n",
       "        0.83495146, 0.83495146, 0.83495146, 0.83495146, 0.83495146,\n",
       "        0.83495146, 0.83495146, 0.83495146, 0.86407767, 0.86407767,\n",
       "        0.86407767, 0.86407767, 0.86407767, 0.86407767, 0.86407767,\n",
       "        0.86407767, 0.86407767, 0.86407767, 0.86407767, 0.86407767,\n",
       "        0.86407767, 0.86407767, 0.86407767, 0.86407767, 0.86407767,\n",
       "        0.86407767, 0.86407767, 0.86407767, 0.86407767, 0.86407767,\n",
       "        0.86407767, 0.86407767, 0.83495146, 0.83495146, 0.83495146,\n",
       "        0.83495146, 0.83495146, 0.83495146, 0.83495146, 0.83495146,\n",
       "        0.83495146, 0.83495146, 0.83495146, 0.83495146, 0.83495146,\n",
       "        0.83495146, 0.83495146, 0.83495146, 0.83495146, 0.83495146,\n",
       "        0.83495146, 0.83495146, 0.83495146, 0.83495146, 0.83495146,\n",
       "        0.83495146, 0.83495146, 0.83495146, 0.83495146, 0.83495146,\n",
       "        0.83495146, 0.83495146, 0.83495146, 0.83495146, 0.82524272,\n",
       "        0.82524272, 0.82524272, 0.82524272, 0.82524272, 0.82524272,\n",
       "        0.82524272, 0.82524272, 0.87378641, 0.87378641, 0.87378641,\n",
       "        0.87378641, 0.87378641, 0.87378641, 0.87378641, 0.87378641,\n",
       "        0.87378641, 0.87378641, 0.87378641, 0.87378641, 0.87378641,\n",
       "        0.87378641, 0.87378641, 0.87378641, 0.87378641, 0.87378641,\n",
       "        0.87378641, 0.87378641, 0.87378641, 0.87378641, 0.87378641,\n",
       "        0.87378641, 0.84466019, 0.84466019, 0.84466019, 0.84466019,\n",
       "        0.84466019, 0.84466019, 0.84466019, 0.84466019, 0.84466019,\n",
       "        0.84466019, 0.84466019, 0.84466019, 0.84466019, 0.84466019,\n",
       "        0.84466019, 0.84466019, 0.84466019, 0.84466019, 0.84466019,\n",
       "        0.84466019, 0.84466019, 0.84466019, 0.84466019, 0.84466019,\n",
       "        0.84466019, 0.84466019, 0.84466019, 0.84466019, 0.84466019,\n",
       "        0.84466019, 0.84466019, 0.84466019, 0.83495146, 0.83495146,\n",
       "        0.83495146, 0.83495146, 0.83495146, 0.83495146, 0.83495146,\n",
       "        0.83495146, 0.85436893, 0.85436893, 0.85436893, 0.85436893,\n",
       "        0.85436893, 0.85436893, 0.85436893, 0.85436893, 0.83495146,\n",
       "        0.83495146, 0.83495146, 0.83495146, 0.83495146, 0.83495146,\n",
       "        0.83495146, 0.85436893, 0.85436893, 0.85436893, 0.85436893,\n",
       "        0.85436893, 0.85436893, 0.85436893, 0.85436893, 0.87378641,\n",
       "        0.84466019, 0.84466019, 0.84466019, 0.84466019, 0.84466019,\n",
       "        0.84466019, 0.84466019, 0.84466019, 0.84466019, 0.84466019,\n",
       "        0.83495146, 0.84466019, 0.84466019, 0.84466019, 0.84466019,\n",
       "        0.83495146, 0.84466019, 0.84466019, 0.84466019, 0.84466019,\n",
       "        0.84466019, 0.84466019, 0.84466019, 0.84466019, 0.84466019,\n",
       "        0.84466019, 0.84466019, 0.84466019, 0.84466019, 0.84466019,\n",
       "        0.84466019, 0.84466019, 0.83495146, 0.83495146, 0.83495146,\n",
       "        0.83495146, 0.83495146, 0.83495146, 0.83495146, 0.83495146,\n",
       "        0.83495146, 0.83495146, 0.83495146, 0.83495146, 0.83495146,\n",
       "        0.83495146, 0.83495146, 0.83495146, 0.84466019, 0.84466019,\n",
       "        0.84466019, 0.84466019, 0.84466019, 0.84466019, 0.84466019,\n",
       "        0.86407767, 0.86407767, 0.86407767, 0.84466019, 0.86407767,\n",
       "        0.84466019, 0.84466019, 0.84466019, 0.88349515, 0.80582524,\n",
       "        0.82524272, 0.82524272, 0.82524272, 0.80582524, 0.82524272,\n",
       "        0.82524272, 0.80582524, 0.82524272, 0.81553398, 0.81553398,\n",
       "        0.82524272, 0.82524272, 0.81553398, 0.82524272, 0.81553398,\n",
       "        0.82524272, 0.82524272, 0.82524272, 0.82524272, 0.82524272,\n",
       "        0.82524272, 0.82524272, 0.82524272, 0.83495146, 0.83495146,\n",
       "        0.83495146, 0.83495146, 0.83495146, 0.83495146, 0.83495146,\n",
       "        0.83495146, 0.83495146, 0.83495146, 0.83495146, 0.83495146,\n",
       "        0.83495146, 0.83495146, 0.83495146, 0.83495146, 0.84466019,\n",
       "        0.83495146, 0.83495146, 0.84466019, 0.84466019, 0.84466019,\n",
       "        0.84466019, 0.84466019, 0.83495146, 0.83495146, 0.83495146,\n",
       "        0.83495146, 0.83495146, 0.83495146, 0.83495146, 0.85436893,\n",
       "        0.83495146, 0.83495146, 0.83495146, 0.85436893, 0.85436893,\n",
       "        0.85436893, 0.85436893, 0.87378641, 0.82524272, 0.82524272,\n",
       "        0.82524272, 0.82524272, 0.82524272, 0.80582524, 0.82524272,\n",
       "        0.80582524, 0.81553398, 0.82524272, 0.82524272, 0.81553398,\n",
       "        0.82524272, 0.81553398, 0.81553398, 0.81553398, 0.82524272,\n",
       "        0.82524272, 0.82524272, 0.82524272, 0.82524272, 0.82524272,\n",
       "        0.82524272, 0.82524272, 0.83495146, 0.83495146, 0.83495146,\n",
       "        0.83495146, 0.83495146, 0.83495146, 0.83495146, 0.83495146,\n",
       "        0.83495146, 0.83495146, 0.83495146, 0.83495146, 0.83495146,\n",
       "        0.83495146, 0.83495146, 0.83495146]),\n",
       " 'split3_test_score': array([0.74509804, 0.74509804, 0.74509804, 0.74509804, 0.74509804,\n",
       "        0.74509804, 0.74509804, 0.74509804, 0.74509804, 0.74509804,\n",
       "        0.74509804, 0.74509804, 0.74509804, 0.74509804, 0.74509804,\n",
       "        0.74509804, 0.74509804, 0.74509804, 0.74509804, 0.74509804,\n",
       "        0.74509804, 0.74509804, 0.74509804, 0.74509804, 0.74509804,\n",
       "        0.74509804, 0.74509804, 0.74509804, 0.74509804, 0.74509804,\n",
       "        0.74509804, 0.74509804, 0.74509804, 0.74509804, 0.74509804,\n",
       "        0.74509804, 0.74509804, 0.74509804, 0.74509804, 0.74509804,\n",
       "        0.74509804, 0.74509804, 0.74509804, 0.74509804, 0.74509804,\n",
       "        0.74509804, 0.74509804, 0.74509804, 0.74509804, 0.74509804,\n",
       "        0.74509804, 0.74509804, 0.74509804, 0.74509804, 0.74509804,\n",
       "        0.74509804, 0.73529412, 0.73529412, 0.73529412, 0.73529412,\n",
       "        0.73529412, 0.73529412, 0.73529412, 0.73529412, 0.7745098 ,\n",
       "        0.7745098 , 0.78431373, 0.78431373, 0.78431373, 0.7745098 ,\n",
       "        0.78431373, 0.78431373, 0.78431373, 0.78431373, 0.78431373,\n",
       "        0.78431373, 0.78431373, 0.78431373, 0.78431373, 0.78431373,\n",
       "        0.78431373, 0.78431373, 0.78431373, 0.78431373, 0.78431373,\n",
       "        0.78431373, 0.78431373, 0.78431373, 0.78431373, 0.78431373,\n",
       "        0.78431373, 0.78431373, 0.78431373, 0.78431373, 0.78431373,\n",
       "        0.78431373, 0.78431373, 0.78431373, 0.78431373, 0.78431373,\n",
       "        0.78431373, 0.78431373, 0.78431373, 0.78431373, 0.78431373,\n",
       "        0.78431373, 0.78431373, 0.78431373, 0.78431373, 0.78431373,\n",
       "        0.78431373, 0.78431373, 0.78431373, 0.78431373, 0.78431373,\n",
       "        0.78431373, 0.78431373, 0.78431373, 0.78431373, 0.78431373,\n",
       "        0.7745098 , 0.7745098 , 0.7745098 , 0.7745098 , 0.7745098 ,\n",
       "        0.7745098 , 0.7745098 , 0.7745098 , 0.79411765, 0.79411765,\n",
       "        0.79411765, 0.79411765, 0.79411765, 0.79411765, 0.79411765,\n",
       "        0.79411765, 0.80392157, 0.80392157, 0.80392157, 0.80392157,\n",
       "        0.80392157, 0.80392157, 0.80392157, 0.80392157, 0.80392157,\n",
       "        0.80392157, 0.80392157, 0.80392157, 0.80392157, 0.80392157,\n",
       "        0.80392157, 0.80392157, 0.80392157, 0.80392157, 0.80392157,\n",
       "        0.80392157, 0.80392157, 0.80392157, 0.80392157, 0.80392157,\n",
       "        0.80392157, 0.80392157, 0.80392157, 0.80392157, 0.80392157,\n",
       "        0.80392157, 0.80392157, 0.80392157, 0.80392157, 0.80392157,\n",
       "        0.80392157, 0.80392157, 0.80392157, 0.80392157, 0.80392157,\n",
       "        0.80392157, 0.79411765, 0.79411765, 0.79411765, 0.79411765,\n",
       "        0.79411765, 0.79411765, 0.79411765, 0.79411765, 0.78431373,\n",
       "        0.78431373, 0.78431373, 0.78431373, 0.78431373, 0.78431373,\n",
       "        0.78431373, 0.78431373, 0.78431373, 0.78431373, 0.78431373,\n",
       "        0.78431373, 0.78431373, 0.78431373, 0.78431373, 0.78431373,\n",
       "        0.78431373, 0.78431373, 0.78431373, 0.78431373, 0.78431373,\n",
       "        0.78431373, 0.78431373, 0.78431373, 0.79411765, 0.79411765,\n",
       "        0.79411765, 0.79411765, 0.79411765, 0.79411765, 0.79411765,\n",
       "        0.79411765, 0.76470588, 0.76470588, 0.76470588, 0.76470588,\n",
       "        0.76470588, 0.76470588, 0.76470588, 0.76470588, 0.76470588,\n",
       "        0.76470588, 0.76470588, 0.76470588, 0.76470588, 0.76470588,\n",
       "        0.76470588, 0.76470588, 0.81372549, 0.81372549, 0.81372549,\n",
       "        0.81372549, 0.81372549, 0.81372549, 0.81372549, 0.81372549,\n",
       "        0.81372549, 0.81372549, 0.81372549, 0.81372549, 0.81372549,\n",
       "        0.81372549, 0.81372549, 0.81372549, 0.81372549, 0.81372549,\n",
       "        0.81372549, 0.81372549, 0.81372549, 0.81372549, 0.81372549,\n",
       "        0.81372549, 0.81372549, 0.81372549, 0.84313725, 0.83333333,\n",
       "        0.84313725, 0.84313725, 0.81372549, 0.84313725, 0.81372549,\n",
       "        0.83333333, 0.84313725, 0.80392157, 0.84313725, 0.81372549,\n",
       "        0.81372549, 0.84313725, 0.8627451 , 0.8627451 , 0.8627451 ,\n",
       "        0.8627451 , 0.8627451 , 0.8627451 , 0.8627451 , 0.8627451 ,\n",
       "        0.84313725, 0.84313725, 0.84313725, 0.84313725, 0.84313725,\n",
       "        0.84313725, 0.84313725, 0.84313725, 0.84313725, 0.84313725,\n",
       "        0.84313725, 0.84313725, 0.84313725, 0.84313725, 0.84313725,\n",
       "        0.84313725, 0.81372549, 0.81372549, 0.81372549, 0.81372549,\n",
       "        0.81372549, 0.81372549, 0.81372549, 0.81372549, 0.79411765,\n",
       "        0.79411765, 0.79411765, 0.79411765, 0.79411765, 0.79411765,\n",
       "        0.79411765, 0.79411765, 0.79411765, 0.79411765, 0.79411765,\n",
       "        0.79411765, 0.79411765, 0.79411765, 0.79411765, 0.79411765,\n",
       "        0.82352941, 0.7745098 , 0.84313725, 0.84313725, 0.82352941,\n",
       "        0.82352941, 0.82352941, 0.83333333, 0.83333333, 0.84313725,\n",
       "        0.78431373, 0.78431373, 0.84313725, 0.79411765, 0.79411765,\n",
       "        0.83333333, 0.82352941, 0.82352941, 0.82352941, 0.81372549,\n",
       "        0.82352941, 0.82352941, 0.81372549, 0.82352941, 0.80392157,\n",
       "        0.80392157, 0.80392157, 0.80392157, 0.80392157, 0.80392157,\n",
       "        0.80392157, 0.80392157, 0.81372549, 0.81372549, 0.81372549,\n",
       "        0.81372549, 0.81372549, 0.81372549, 0.81372549, 0.81372549,\n",
       "        0.81372549, 0.81372549, 0.81372549, 0.81372549, 0.81372549,\n",
       "        0.81372549, 0.81372549, 0.81372549, 0.79411765, 0.79411765,\n",
       "        0.79411765, 0.79411765, 0.79411765, 0.79411765, 0.79411765,\n",
       "        0.79411765, 0.79411765, 0.79411765, 0.79411765, 0.79411765,\n",
       "        0.79411765, 0.79411765, 0.79411765, 0.79411765, 0.76470588,\n",
       "        0.76470588, 0.7745098 , 0.75490196, 0.74509804, 0.75490196,\n",
       "        0.78431373, 0.79411765, 0.78431373, 0.83333333, 0.84313725,\n",
       "        0.8627451 , 0.80392157, 0.85294118, 0.81372549, 0.80392157,\n",
       "        0.82352941, 0.83333333, 0.82352941, 0.83333333, 0.83333333,\n",
       "        0.82352941, 0.83333333, 0.83333333, 0.81372549, 0.81372549,\n",
       "        0.81372549, 0.81372549, 0.81372549, 0.81372549, 0.81372549,\n",
       "        0.81372549, 0.82352941, 0.82352941, 0.82352941, 0.82352941,\n",
       "        0.82352941, 0.82352941, 0.82352941, 0.82352941, 0.81372549,\n",
       "        0.81372549, 0.81372549, 0.81372549, 0.81372549, 0.81372549,\n",
       "        0.81372549, 0.81372549, 0.79411765, 0.79411765, 0.79411765,\n",
       "        0.79411765, 0.79411765, 0.79411765, 0.79411765, 0.79411765,\n",
       "        0.79411765, 0.79411765, 0.79411765, 0.79411765, 0.79411765,\n",
       "        0.79411765, 0.79411765, 0.79411765]),\n",
       " 'split4_test_score': array([0.79207921, 0.79207921, 0.79207921, 0.79207921, 0.79207921,\n",
       "        0.79207921, 0.79207921, 0.79207921, 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.79207921,\n",
       "        0.79207921, 0.79207921, 0.79207921, 0.79207921, 0.79207921,\n",
       "        0.79207921, 0.79207921, 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.79207921, 0.79207921,\n",
       "        0.79207921, 0.79207921, 0.79207921, 0.79207921, 0.79207921,\n",
       "        0.79207921, 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.79207921, 0.79207921, 0.79207921, 0.79207921,\n",
       "        0.79207921, 0.79207921, 0.79207921, 0.79207921, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.8019802 , 0.8019802 , 0.76237624, 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.75247525, 0.75247525, 0.75247525, 0.79207921, 0.79207921,\n",
       "        0.79207921, 0.79207921, 0.79207921, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.79207921, 0.79207921,\n",
       "        0.79207921, 0.79207921, 0.79207921, 0.79207921, 0.79207921,\n",
       "        0.79207921, 0.83168317, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.83168317, 0.79207921,\n",
       "        0.79207921, 0.75247525, 0.79207921, 0.79207921, 0.79207921,\n",
       "        0.79207921, 0.79207921, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 ,\n",
       "        0.84158416, 0.84158416, 0.84158416, 0.84158416, 0.84158416,\n",
       "        0.84158416, 0.84158416, 0.84158416]),\n",
       " 'split5_test_score': array([0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.81188119, 0.81188119,\n",
       "        0.82178218, 0.81188119, 0.81188119, 0.82178218, 0.82178218,\n",
       "        0.81188119, 0.82178218, 0.82178218, 0.82178218, 0.81188119,\n",
       "        0.82178218, 0.81188119, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.83168317, 0.82178218, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.82178218, 0.81188119, 0.82178218, 0.82178218, 0.81188119,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.82178218, 0.82178218,\n",
       "        0.81188119, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.82178218, 0.83168317, 0.82178218, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.83168317, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.81188119, 0.82178218, 0.81188119,\n",
       "        0.83168317, 0.82178218, 0.82178218, 0.83168317, 0.82178218,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.84158416, 0.84158416,\n",
       "        0.84158416, 0.84158416, 0.84158416, 0.84158416, 0.84158416,\n",
       "        0.84158416, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.82178218, 0.82178218, 0.82178218, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.81188119, 0.81188119, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.83168317, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.81188119, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.82178218,\n",
       "        0.82178218, 0.81188119, 0.84158416, 0.83168317, 0.84158416,\n",
       "        0.83168317, 0.84158416, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.84158416, 0.84158416, 0.83168317, 0.83168317,\n",
       "        0.84158416, 0.83168317, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.83168317, 0.84158416, 0.84158416, 0.84158416, 0.84158416,\n",
       "        0.84158416, 0.84158416, 0.84158416, 0.84158416, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119]),\n",
       " 'split6_test_score': array([0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.81188119, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.84158416, 0.82178218,\n",
       "        0.84158416, 0.82178218, 0.85148515, 0.83168317, 0.85148515,\n",
       "        0.82178218, 0.84158416, 0.84158416, 0.84158416, 0.84158416,\n",
       "        0.84158416, 0.84158416, 0.84158416, 0.84158416, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.8019802 , 0.8019802 , 0.8019802 , 0.8019802 , 0.82178218,\n",
       "        0.8019802 , 0.8019802 , 0.82178218, 0.84158416, 0.84158416,\n",
       "        0.84158416, 0.82178218, 0.82178218, 0.84158416, 0.82178218,\n",
       "        0.84158416, 0.81188119, 0.81188119, 0.83168317, 0.81188119,\n",
       "        0.83168317, 0.83168317, 0.81188119, 0.81188119, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.82178218, 0.84158416, 0.84158416,\n",
       "        0.81188119, 0.85148515, 0.85148515, 0.81188119, 0.82178218,\n",
       "        0.84158416, 0.84158416, 0.84158416, 0.84158416, 0.84158416,\n",
       "        0.84158416, 0.84158416, 0.84158416, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.8019802 , 0.81188119, 0.8019802 , 0.8019802 ,\n",
       "        0.81188119, 0.8019802 , 0.81188119, 0.81188119, 0.8019802 ,\n",
       "        0.8019802 , 0.8019802 , 0.81188119, 0.81188119, 0.8019802 ,\n",
       "        0.8019802 , 0.81188119, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.84158416, 0.84158416,\n",
       "        0.84158416, 0.84158416, 0.84158416, 0.84158416, 0.84158416,\n",
       "        0.84158416, 0.8019802 , 0.79207921, 0.8019802 , 0.84158416,\n",
       "        0.81188119, 0.83168317, 0.85148515, 0.82178218, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.81188119, 0.81188119, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.81188119, 0.81188119, 0.82178218, 0.82178218,\n",
       "        0.81188119, 0.81188119, 0.81188119, 0.82178218, 0.82178218,\n",
       "        0.81188119, 0.85148515, 0.85148515, 0.85148515, 0.85148515,\n",
       "        0.85148515, 0.85148515, 0.85148515, 0.85148515, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.84158416, 0.84158416, 0.84158416,\n",
       "        0.84158416, 0.84158416, 0.84158416, 0.84158416, 0.84158416,\n",
       "        0.83168317, 0.81188119, 0.8019802 , 0.82178218, 0.82178218,\n",
       "        0.85148515, 0.82178218, 0.82178218, 0.85148515, 0.84158416,\n",
       "        0.85148515, 0.85148515, 0.85148515, 0.83168317, 0.84158416,\n",
       "        0.84158416, 0.83168317, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.83168317, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.81188119, 0.81188119, 0.82178218,\n",
       "        0.81188119, 0.82178218, 0.8019802 , 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.8019802 , 0.81188119, 0.82178218,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.83168317, 0.84158416, 0.84158416, 0.84158416, 0.84158416,\n",
       "        0.84158416, 0.84158416, 0.84158416, 0.84158416, 0.83168317,\n",
       "        0.83168317, 0.82178218, 0.82178218, 0.84158416, 0.85148515,\n",
       "        0.85148515, 0.81188119, 0.85148515, 0.85148515, 0.85148515,\n",
       "        0.85148515, 0.85148515, 0.83168317, 0.83168317, 0.84158416,\n",
       "        0.82178218, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.82178218, 0.82178218, 0.83168317, 0.82178218, 0.81188119,\n",
       "        0.81188119, 0.82178218, 0.82178218, 0.82178218, 0.82178218,\n",
       "        0.81188119, 0.82178218, 0.81188119, 0.81188119, 0.81188119,\n",
       "        0.81188119, 0.81188119, 0.82178218, 0.81188119, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.83168317, 0.83168317, 0.83168317, 0.83168317, 0.83168317,\n",
       "        0.84158416, 0.84158416, 0.84158416, 0.84158416, 0.84158416,\n",
       "        0.84158416, 0.84158416, 0.84158416]),\n",
       " 'mean_test_score': array([0.79271709, 0.79271709, 0.79271709, 0.79271709, 0.79271709,\n",
       "        0.79271709, 0.79271709, 0.79271709, 0.79551821, 0.79551821,\n",
       "        0.79551821, 0.79551821, 0.79551821, 0.79551821, 0.79551821,\n",
       "        0.79551821, 0.79551821, 0.79551821, 0.79551821, 0.79551821,\n",
       "        0.79551821, 0.79551821, 0.79551821, 0.79551821, 0.79551821,\n",
       "        0.79551821, 0.79551821, 0.79551821, 0.79551821, 0.79551821,\n",
       "        0.79551821, 0.79551821, 0.79551821, 0.79551821, 0.79551821,\n",
       "        0.79551821, 0.79551821, 0.79551821, 0.79551821, 0.79551821,\n",
       "        0.79831933, 0.79831933, 0.79831933, 0.79831933, 0.79831933,\n",
       "        0.79831933, 0.79831933, 0.79831933, 0.79551821, 0.79551821,\n",
       "        0.79551821, 0.79551821, 0.79551821, 0.79551821, 0.79551821,\n",
       "        0.79551821, 0.79411765, 0.79411765, 0.79411765, 0.79411765,\n",
       "        0.79411765, 0.79411765, 0.79411765, 0.79411765, 0.78991597,\n",
       "        0.78991597, 0.79131653, 0.79131653, 0.79131653, 0.78991597,\n",
       "        0.79131653, 0.79131653, 0.79411765, 0.79411765, 0.79411765,\n",
       "        0.79411765, 0.79411765, 0.79411765, 0.79411765, 0.79411765,\n",
       "        0.79131653, 0.79131653, 0.79131653, 0.79131653, 0.79131653,\n",
       "        0.79131653, 0.79131653, 0.79131653, 0.79551821, 0.79551821,\n",
       "        0.79551821, 0.79551821, 0.79551821, 0.79551821, 0.79551821,\n",
       "        0.79551821, 0.79551821, 0.79551821, 0.79551821, 0.79551821,\n",
       "        0.79551821, 0.79551821, 0.79551821, 0.79551821, 0.79831933,\n",
       "        0.79831933, 0.79831933, 0.79831933, 0.79831933, 0.79831933,\n",
       "        0.79831933, 0.79831933, 0.79971989, 0.79971989, 0.79971989,\n",
       "        0.79971989, 0.79971989, 0.79971989, 0.79971989, 0.79971989,\n",
       "        0.80112045, 0.80112045, 0.80112045, 0.80112045, 0.80112045,\n",
       "        0.80112045, 0.80112045, 0.80112045, 0.78431373, 0.78151261,\n",
       "        0.78431373, 0.78151261, 0.78571429, 0.78291317, 0.78711485,\n",
       "        0.78291317, 0.78851541, 0.78851541, 0.78711485, 0.78711485,\n",
       "        0.78851541, 0.78711485, 0.78851541, 0.78991597, 0.78711485,\n",
       "        0.78571429, 0.78711485, 0.78711485, 0.78711485, 0.78571429,\n",
       "        0.78711485, 0.78571429, 0.78291317, 0.78291317, 0.78011204,\n",
       "        0.78011204, 0.78011204, 0.78291317, 0.78291317, 0.78291317,\n",
       "        0.78851541, 0.78851541, 0.78851541, 0.78851541, 0.79131653,\n",
       "        0.78851541, 0.78851541, 0.79131653, 0.79551821, 0.79551821,\n",
       "        0.79551821, 0.79271709, 0.79271709, 0.79551821, 0.79271709,\n",
       "        0.79551821, 0.78851541, 0.78851541, 0.79131653, 0.78851541,\n",
       "        0.79131653, 0.79131653, 0.78851541, 0.78851541, 0.79691877,\n",
       "        0.79691877, 0.79691877, 0.79691877, 0.79691877, 0.79691877,\n",
       "        0.79691877, 0.79691877, 0.79691877, 0.79971989, 0.79971989,\n",
       "        0.79551821, 0.79971989, 0.80112045, 0.79691877, 0.79831933,\n",
       "        0.79971989, 0.79971989, 0.79971989, 0.79971989, 0.79831933,\n",
       "        0.80112045, 0.80252101, 0.80252101, 0.79831933, 0.79831933,\n",
       "        0.79831933, 0.79831933, 0.79971989, 0.80112045, 0.79971989,\n",
       "        0.79971989, 0.78991597, 0.79131653, 0.78991597, 0.78991597,\n",
       "        0.79131653, 0.78991597, 0.79131653, 0.79131653, 0.78011204,\n",
       "        0.77871148, 0.78011204, 0.78011204, 0.78011204, 0.78011204,\n",
       "        0.77871148, 0.78011204, 0.78711485, 0.78711485, 0.78711485,\n",
       "        0.78711485, 0.78711485, 0.78711485, 0.78711485, 0.78711485,\n",
       "        0.79131653, 0.79131653, 0.79131653, 0.79131653, 0.79131653,\n",
       "        0.79131653, 0.79131653, 0.79131653, 0.79691877, 0.79691877,\n",
       "        0.79691877, 0.79691877, 0.79691877, 0.79691877, 0.79691877,\n",
       "        0.79691877, 0.79831933, 0.79971989, 0.79271709, 0.80812325,\n",
       "        0.80672269, 0.80952381, 0.80812325, 0.80672269, 0.80112045,\n",
       "        0.80392157, 0.80532213, 0.80252101, 0.80812325, 0.80252101,\n",
       "        0.80532213, 0.81232493, 0.80392157, 0.80532213, 0.80392157,\n",
       "        0.80812325, 0.80532213, 0.80532213, 0.80672269, 0.80812325,\n",
       "        0.80532213, 0.80532213, 0.80672269, 0.80672269, 0.80672269,\n",
       "        0.80672269, 0.80532213, 0.80532213, 0.80392157, 0.80392157,\n",
       "        0.80112045, 0.80252101, 0.80252101, 0.80532213, 0.80392157,\n",
       "        0.80252101, 0.79691877, 0.79691877, 0.79691877, 0.79691877,\n",
       "        0.79691877, 0.79691877, 0.79691877, 0.79691877, 0.79411765,\n",
       "        0.79411765, 0.79411765, 0.79411765, 0.79411765, 0.79411765,\n",
       "        0.79411765, 0.79411765, 0.80392157, 0.80392157, 0.80392157,\n",
       "        0.80392157, 0.80392157, 0.80392157, 0.80392157, 0.80392157,\n",
       "        0.78431373, 0.77310924, 0.78431373, 0.79271709, 0.79551821,\n",
       "        0.79691877, 0.79691877, 0.79971989, 0.80812325, 0.80952381,\n",
       "        0.80112045, 0.79831933, 0.80812325, 0.79831933, 0.80252101,\n",
       "        0.81092437, 0.80252101, 0.80112045, 0.79691877, 0.79831933,\n",
       "        0.79691877, 0.79831933, 0.79551821, 0.80392157, 0.78851541,\n",
       "        0.79131653, 0.79131653, 0.78991597, 0.78711485, 0.78991597,\n",
       "        0.78991597, 0.78851541, 0.79131653, 0.79131653, 0.79131653,\n",
       "        0.79131653, 0.79271709, 0.78851541, 0.79271709, 0.79271709,\n",
       "        0.79131653, 0.79131653, 0.79131653, 0.79131653, 0.79131653,\n",
       "        0.79131653, 0.79131653, 0.79131653, 0.79271709, 0.79271709,\n",
       "        0.79271709, 0.79271709, 0.79271709, 0.79271709, 0.79271709,\n",
       "        0.79271709, 0.80532213, 0.80532213, 0.80532213, 0.80532213,\n",
       "        0.80532213, 0.80532213, 0.80532213, 0.80532213, 0.78711485,\n",
       "        0.78851541, 0.77871148, 0.78851541, 0.78991597, 0.79691877,\n",
       "        0.79971989, 0.79691877, 0.80252101, 0.80812325, 0.81092437,\n",
       "        0.81372549, 0.80532213, 0.80812325, 0.80672269, 0.80812325,\n",
       "        0.80112045, 0.80532213, 0.80392157, 0.80532213, 0.80532213,\n",
       "        0.80672269, 0.80672269, 0.81092437, 0.79691877, 0.79551821,\n",
       "        0.79551821, 0.79551821, 0.79691877, 0.79411765, 0.79691877,\n",
       "        0.79131653, 0.79691877, 0.79691877, 0.79831933, 0.79551821,\n",
       "        0.79691877, 0.79551821, 0.79691877, 0.79551821, 0.79551821,\n",
       "        0.79551821, 0.79551821, 0.79551821, 0.79551821, 0.79551821,\n",
       "        0.79551821, 0.79551821, 0.79411765, 0.79411765, 0.79411765,\n",
       "        0.79411765, 0.79411765, 0.79411765, 0.79411765, 0.79411765,\n",
       "        0.80672269, 0.80672269, 0.80672269, 0.80672269, 0.80672269,\n",
       "        0.80672269, 0.80672269, 0.80672269]),\n",
       " 'std_test_score': array([0.03081579, 0.03081579, 0.03081579, 0.03081579, 0.03081579,\n",
       "        0.03081579, 0.03081579, 0.03081579, 0.03037393, 0.03037393,\n",
       "        0.03037393, 0.03037393, 0.03037393, 0.03037393, 0.03037393,\n",
       "        0.03037393, 0.03037393, 0.03037393, 0.03037393, 0.03037393,\n",
       "        0.03037393, 0.03037393, 0.03037393, 0.03037393, 0.03037393,\n",
       "        0.03037393, 0.03037393, 0.03037393, 0.03037393, 0.03037393,\n",
       "        0.03037393, 0.03037393, 0.03037393, 0.03037393, 0.03037393,\n",
       "        0.03037393, 0.03037393, 0.03037393, 0.03037393, 0.03037393,\n",
       "        0.03029986, 0.03029986, 0.03029986, 0.03029986, 0.03029986,\n",
       "        0.03029986, 0.03029986, 0.03029986, 0.03037393, 0.03037393,\n",
       "        0.03037393, 0.03037393, 0.03037393, 0.03037393, 0.03037393,\n",
       "        0.03037393, 0.03279601, 0.03279601, 0.03279601, 0.03279601,\n",
       "        0.03279601, 0.03279601, 0.03279601, 0.03279601, 0.03277356,\n",
       "        0.03277356, 0.03229119, 0.03229119, 0.03229119, 0.03277356,\n",
       "        0.03229119, 0.03229119, 0.03113101, 0.03113101, 0.03113101,\n",
       "        0.03113101, 0.03113101, 0.03113101, 0.03113101, 0.03113101,\n",
       "        0.0283956 , 0.0283956 , 0.0283956 , 0.0283956 , 0.0283956 ,\n",
       "        0.0283956 , 0.0283956 , 0.0283956 , 0.02553864, 0.02553864,\n",
       "        0.02553864, 0.02553864, 0.02553864, 0.02553864, 0.02553864,\n",
       "        0.02553864, 0.02553864, 0.02553864, 0.02553864, 0.02553864,\n",
       "        0.02553864, 0.02553864, 0.02553864, 0.02553864, 0.03089798,\n",
       "        0.03089798, 0.03089798, 0.03089798, 0.03089798, 0.03089798,\n",
       "        0.03089798, 0.03089798, 0.03466522, 0.03466522, 0.03466522,\n",
       "        0.03466522, 0.03466522, 0.03466522, 0.03466522, 0.03466522,\n",
       "        0.03105578, 0.03105578, 0.03105578, 0.03105578, 0.03105578,\n",
       "        0.03105578, 0.03105578, 0.03105578, 0.06671482, 0.06463471,\n",
       "        0.06671482, 0.06463471, 0.06799407, 0.06559231, 0.06668137,\n",
       "        0.06334529, 0.06462158, 0.06462158, 0.06398961, 0.06398961,\n",
       "        0.06462158, 0.06398961, 0.06256163, 0.06317684, 0.06123298,\n",
       "        0.06053326, 0.06123298, 0.06123298, 0.06123298, 0.06053326,\n",
       "        0.06123298, 0.06053326, 0.05663441, 0.05663441, 0.05511192,\n",
       "        0.05511192, 0.05511192, 0.05663441, 0.05663441, 0.05663441,\n",
       "        0.04004958, 0.04004958, 0.04004958, 0.04004958, 0.04155747,\n",
       "        0.04004958, 0.04004958, 0.04155747, 0.0427385 , 0.0427385 ,\n",
       "        0.0427385 , 0.0402011 , 0.0402011 , 0.0427385 , 0.0402011 ,\n",
       "        0.0427385 , 0.03874522, 0.03874522, 0.04098432, 0.03874522,\n",
       "        0.04098432, 0.04098432, 0.03874522, 0.03874522, 0.0317241 ,\n",
       "        0.0317241 , 0.0317241 , 0.0317241 , 0.0317241 , 0.0317241 ,\n",
       "        0.0317241 , 0.0317241 , 0.04819021, 0.050092  , 0.050092  ,\n",
       "        0.04758735, 0.05064263, 0.05136517, 0.04598582, 0.04656729,\n",
       "        0.05008125, 0.04739346, 0.05008125, 0.05008125, 0.04958062,\n",
       "        0.047876  , 0.04640855, 0.04640855, 0.04601386, 0.04601386,\n",
       "        0.04601386, 0.04601386, 0.04364835, 0.04417181, 0.04655286,\n",
       "        0.04364835, 0.03748467, 0.03808936, 0.03748467, 0.03748467,\n",
       "        0.03808936, 0.03748467, 0.03808936, 0.03808936, 0.0512412 ,\n",
       "        0.0522345 , 0.0512412 , 0.05296723, 0.05296723, 0.0512412 ,\n",
       "        0.0522345 , 0.05296723, 0.05436555, 0.05436555, 0.05436555,\n",
       "        0.05436555, 0.05436555, 0.05436555, 0.05436555, 0.05436555,\n",
       "        0.05383767, 0.05383767, 0.05383767, 0.05383767, 0.05383767,\n",
       "        0.05383767, 0.05383767, 0.05383767, 0.04607971, 0.04607971,\n",
       "        0.04607971, 0.04607971, 0.04607971, 0.04607971, 0.04607971,\n",
       "        0.04607971, 0.03659164, 0.03555901, 0.04699673, 0.04155168,\n",
       "        0.03833197, 0.03931743, 0.0395553 , 0.04061705, 0.03230443,\n",
       "        0.03407742, 0.03543199, 0.03090059, 0.03404188, 0.03294881,\n",
       "        0.02871124, 0.03449453, 0.05045056, 0.05078839, 0.05045056,\n",
       "        0.04873029, 0.05078839, 0.05078839, 0.05135633, 0.05385886,\n",
       "        0.04011191, 0.04011191, 0.04048757, 0.04048757, 0.04048757,\n",
       "        0.04048757, 0.04011191, 0.04011191, 0.04553203, 0.04553203,\n",
       "        0.04391629, 0.04511143, 0.04511143, 0.04420586, 0.04553203,\n",
       "        0.0426319 , 0.05006225, 0.05006225, 0.05006225, 0.05006225,\n",
       "        0.05006225, 0.05006225, 0.05006225, 0.05006225, 0.04053753,\n",
       "        0.04053753, 0.04053753, 0.04053753, 0.04053753, 0.04053753,\n",
       "        0.04053753, 0.04053753, 0.03029732, 0.03029732, 0.03029732,\n",
       "        0.03029732, 0.03029732, 0.03029732, 0.03029732, 0.03029732,\n",
       "        0.04936411, 0.04881279, 0.05029177, 0.04978175, 0.04189018,\n",
       "        0.05030017, 0.04006154, 0.03950601, 0.04356057, 0.04076655,\n",
       "        0.04287978, 0.04477502, 0.04424338, 0.04229394, 0.0395848 ,\n",
       "        0.04373037, 0.05713254, 0.05651855, 0.05685367, 0.05908823,\n",
       "        0.05685367, 0.05374187, 0.05264601, 0.05994658, 0.04307504,\n",
       "        0.04470992, 0.04470992, 0.04388103, 0.04212102, 0.04529413,\n",
       "        0.04388103, 0.04307504, 0.04259637, 0.04215156, 0.04215156,\n",
       "        0.04404459, 0.04308394, 0.04250775, 0.04308394, 0.04296817,\n",
       "        0.0474013 , 0.0474013 , 0.0474013 , 0.0474013 , 0.0474013 ,\n",
       "        0.0474013 , 0.0474013 , 0.0474013 , 0.03615008, 0.03615008,\n",
       "        0.03615008, 0.03615008, 0.03615008, 0.03615008, 0.03615008,\n",
       "        0.03615008, 0.03130275, 0.03130275, 0.03130275, 0.03130275,\n",
       "        0.03130275, 0.03130275, 0.03130275, 0.03130275, 0.04479797,\n",
       "        0.03976667, 0.04169937, 0.04607539, 0.0461091 , 0.04491594,\n",
       "        0.04051728, 0.03710584, 0.03706716, 0.03997967, 0.03862213,\n",
       "        0.03922762, 0.03374383, 0.03740956, 0.02923377, 0.03598853,\n",
       "        0.04346228, 0.04603299, 0.04530279, 0.05035725, 0.05035725,\n",
       "        0.0476731 , 0.04743152, 0.05108289, 0.03998525, 0.03925659,\n",
       "        0.03925659, 0.04083006, 0.03998525, 0.03855758, 0.03998525,\n",
       "        0.03843963, 0.04906724, 0.04916865, 0.04842891, 0.04847529,\n",
       "        0.04916865, 0.04847529, 0.04906724, 0.04847529, 0.04943321,\n",
       "        0.04943321, 0.04943321, 0.04943321, 0.04943321, 0.04943321,\n",
       "        0.04943321, 0.04943321, 0.03628976, 0.03628976, 0.03628976,\n",
       "        0.03628976, 0.03628976, 0.03628976, 0.03628976, 0.03628976,\n",
       "        0.03264366, 0.03264366, 0.03264366, 0.03264366, 0.03264366,\n",
       "        0.03264366, 0.03264366, 0.03264366]),\n",
       " 'rank_test_score': array([299, 299, 299, 299, 299, 299, 299, 299, 188, 188, 188, 188, 188,\n",
       "        188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188,\n",
       "        188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188,\n",
       "        188, 121, 121, 121, 121, 121, 121, 121, 121, 188, 188, 188, 188,\n",
       "        188, 188, 188, 188, 266, 266, 266, 266, 266, 266, 266, 266, 368,\n",
       "        368, 323, 323, 323, 368, 323, 323, 266, 266, 266, 266, 266, 266,\n",
       "        266, 266, 323, 323, 323, 323, 323, 323, 323, 323, 188, 188, 188,\n",
       "        188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188, 188,\n",
       "        121, 121, 121, 121, 121, 121, 121, 121, 100, 100, 100, 100, 100,\n",
       "        100, 100, 100,  84,  84,  84,  84,  84,  84,  84,  84, 423, 434,\n",
       "        423, 434, 419, 427, 400, 427, 380, 380, 400, 400, 380, 400, 380,\n",
       "        368, 400, 419, 400, 400, 400, 419, 400, 419, 427, 427, 436, 436,\n",
       "        436, 427, 427, 427, 380, 380, 380, 380, 323, 380, 380, 323, 188,\n",
       "        188, 188, 299, 299, 188, 299, 188, 380, 380, 323, 380, 323, 323,\n",
       "        380, 380, 149, 149, 149, 149, 149, 149, 149, 149, 149, 100, 100,\n",
       "        188, 100,  84, 149, 121, 100, 100, 100, 100, 121,  84,  74,  74,\n",
       "        121, 121, 121, 121, 100,  84, 100, 100, 368, 323, 368, 368, 323,\n",
       "        368, 323, 323, 436, 445, 436, 436, 436, 436, 445, 436, 400, 400,\n",
       "        400, 400, 400, 400, 400, 400, 323, 323, 323, 323, 323, 323, 323,\n",
       "        323, 149, 149, 149, 149, 149, 149, 149, 149, 121, 100, 299,   8,\n",
       "         18,   6,   8,  18,  84,  58,  36,  74,   8,  74,  36,   2,  58,\n",
       "         36,  58,   8,  36,  36,  18,   8,  36,  36,  18,  18,  18,  18,\n",
       "         36,  36,  58,  58,  84,  74,  74,  36,  58,  74, 149, 149, 149,\n",
       "        149, 149, 149, 149, 149, 266, 266, 266, 266, 266, 266, 266, 266,\n",
       "         58,  58,  58,  58,  58,  58,  58,  58, 423, 448, 423, 299, 188,\n",
       "        149, 149, 100,   8,   6,  84, 121,   8, 121,  74,   3,  74,  84,\n",
       "        149, 121, 149, 121, 188,  58, 380, 323, 323, 368, 400, 368, 368,\n",
       "        380, 323, 323, 323, 323, 299, 380, 299, 299, 323, 323, 323, 323,\n",
       "        323, 323, 323, 323, 299, 299, 299, 299, 299, 299, 299, 299,  36,\n",
       "         36,  36,  36,  36,  36,  36,  36, 400, 380, 445, 380, 368, 149,\n",
       "        100, 149,  74,   8,   3,   1,  36,   8,  18,   8,  84,  36,  58,\n",
       "         36,  36,  18,  18,   3, 149, 188, 188, 188, 149, 266, 149, 323,\n",
       "        149, 149, 121, 188, 149, 188, 149, 188, 188, 188, 188, 188, 188,\n",
       "        188, 188, 188, 266, 266, 266, 266, 266, 266, 266, 266,  18,  18,\n",
       "         18,  18,  18,  18,  18,  18])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble (Sneak Peak)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's better than a decision tree ? Two decision Trees !\n",
    "\n",
    "It's a fact that multiple learners often lead to better performances. Let's see `AdaBoostRegressor`, an enemble Decision Tree with Boosting Method (Don't worry, we'll talk about this later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "regr_2 = AdaBoostRegressor(DecisionTreeRegressor(max_depth=4),\n",
    "                          n_estimators=200, random_state=rng)\n",
    "regr_2.fit(X, y)\n",
    "y_2 = regr_2.predict(X)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure()\n",
    "plt.scatter(X, y, c=\"k\", label=\"training samples\")\n",
    "plt.plot(X, y_1, c=\"g\", label=\"n_tree=1\", linewidth=2)\n",
    "plt.plot(X, y_2, c=\"r\", label=\"n_tree=200\", linewidth=2)\n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"target\")\n",
    "plt.title(\"Boosted Decision Tree Regression\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Pros:\n",
    "- Easy to interpret\n",
    "\n",
    "\n",
    "Cons:\n",
    "- Sensitive to Outlier/Noise\n",
    "- Biased with imbalance data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sources: \n",
    "[Datacamp](https://www.datacamp.com/community/tutorials/decision-tree-classification-python), \n",
    "[Greyatom](https://medium.com/greyatom/decision-trees-a-simple-way-to-visualize-a-decision-dc506a403aeb),\n",
    "[random_state](https://stackoverflow.com/questions/39158003/confused-about-random-state-in-decision-tree-of-scikit-learn), \n",
    "[scikit-learn doc](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html),\n",
    "[sklearn post prune](https://scikit-learn.org/dev/auto_examples/tree/plot_cost_complexity_pruning.html),\n",
    "[Sklearn GridCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html),"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
